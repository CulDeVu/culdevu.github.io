<html>
	<head>
		<meta charset="UTF-8">
		
		<style>
			body {
				-webkit-text-size-adjust: none;
				-moz-text-size-adjust: none;
				-ms-text-size-adjust: none;

				word-wrap: break-word;
				font-family: sans-serif;
				line-height: 1.2rem;
			}

			.nav {
				display: inline-block;
			}

			.navitem {
				display: inline-block;

				padding: 10px;
				min-width: 100px;
				text-align: center;

				color: #fff;
				text-decoration: none;

				transition: background 0.25s ease;
			}

			.navitem:hover {
				background: #b50;
				/*color: #fa0;*/
				transition: background 0.125s ease;
				color: #fff;
			}

			/* 4*(navitem-width + 2*navitem-padding) + 2*body-padding = 4*(100px + 10px) + 2*(10px) = 500px */
			@media (max-width: 500px) { 
				.navitem {
					width: calc(50% - 20px);
				}
			}

			.codeblock {
				border: 1px solid;
				padding: 1em;
				overflow: auto;
			}

			.codeinline {
				border: 1px solid #aaa;
				border-radius: 3px;
				background-color: #e6e6e6;

				/* Not very good. Will probably depend on the metrics of the font used. Oh well. */
				padding-left: 0.1em;
				padding-right: 0.1em;
			}

			.primary_link {
				color: #000;
				text-decoration: none;
			}
			.primary_link:hover {
				color: #b50;
				text-decoration: none;
			}

			/* For dealing with img()[] elements */
			figure {
				border: 1px solid #888;
				background-color: #e6e6e6;

				margin: 0;
				padding: 1ch;

				display: inline-flex;
				flex-flow: column;
			}
			figcaption {
				margin-top: 0.5rem;
				align-self: center;
			}
			img {
				align-self: center;
				max-width:100%%
			}

			blockquote {
				margin: 0;
				padding-left: 2ch;
				padding-top: 1em;
				padding-bottom: 1em;
				padding-right: 2ch;
				border: 1px solid #888;
				background-color: #e6e6e6;
				border-radius: 3px;

				font-style: italic;
			}

			h2 {
				font-size: 1.25rem;
			}

			.section_heading {
				border-top: 1px dotted;
				padding-top: 1rem;
			}

		</style>

		<meta name="viewport" content="width=device-width, initial-scale=1">
	</head>
	<body style="max-width:980px; padding: 10px; margin:auto; background: #e6e6e6">
		<div style="background: #fafafa; padding: 20px">
			<div><h1 style="margin-top: 0.5em; margin-bottom: 0.3em">djtaylor.me</h1></div>
			<div><i>Insert tagline here</i></div>
		</div>
		<div style="background: #222; color: #fafafa">
			<a href="/" class="navitem">Blog</a><a href="/thought/" class="navitem">Thoughts</a><a href="/portfolio/" class="navitem">Projects</a><a href="/resume/" class="navitem">Resume</a><a href="/physics/" class="navitem">Physics</a>
		</div>

		<div style="background: #fafafa; padding: 20px"><h2 style="margin-bottom:0.5rem">Gezira</h2><i>Pub. 2025 Sep 30</i><p>[todo:- consistant cap on gezira/Gezira- consistant use of Nile vs Gezira. Do I even want to make the distinction?- caption all images]</p><h3 class="section_heading">VPRI</h3><p>In 2001 Alan Kay co-founded the Viewpoints Research Institute, or VPRI. It started as an outreach organization for Squeak, but around 2006 it shifted focus to research.</p><p>It was a typical Alan Kay endeavor: reinvent computing in the image of whatever has been on his mind recently. This time it's source code size. In my own words, I'd say the problem statement is "can we make a computing system that has 95% of the functionality, 95% of the ease of use, but 1/10000th of the lines of code of systems today?", where "today" meant 2005. He often mentioned a target of 20kLOC for the whole computing stack.</p><p>Their primary output were research papers and NSF progress reports. These are listed <a href="https://tinlizzie.org/IA/index.php/Papers_from_Viewpoints_Research_Institute">here</a>.</p><p>The main vehicle by which they worked towards their goal is a program they created called Frank. Frank is one of those document-centric computing models. Documents could embed text, images, programs, etc. I don't think the source code to Frank was ever released. I've seen multiple people online talk about running Frank, but I don't know where they found the source.</p><p>The VPRI's <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=0639876">5-year NSF grant</a> concluded in 2012. After that the VPRI slowed down significantly. Their website lists 2018 as the official end of the institute, but Alan Kay is listed as an author to only 2 papers after 2013, down from multiple papers a year. In 2016 the VPRI joined Y-Combinator's HARC, during which not much is known publicly. [todo: more?]</p><h3 class="section_heading">Gezira</h3><p>In all the annual NSF progress reports, a big deal is made about the rendering system. That's what I want to talk about.</p><p>The goal was to come up with a way to do all of the 2D graphics necessary to power Frank. It would need to render text and shapes and such in as few lines of code as possible. They would do this by creating language that could efficiently describe how to render, and compilers that could translate this description into a runnable artifact.</p><p>This was spearheaded by a man named Daniel Amelang. He was a contributor to the Cairo graphics library in 2006 and 2007. He joined the VPRI to work on the graphics problem. The goal was to create a graphics system that would support all of the major features of Cairo, but in much less code.</p><p>The end result was Gezira, a renderer written in just a couple hundred lines. It supports beziers, fills, strokes, antialiasing, some limited texture filtering, many compositors, different caps and joins. It was written in a custom DSL made for the task. It was run in Nile, a custom stream processor also made for the task. There were other things in the mix, like a grammar parser called OMeta, and scheme variant called Maru. But in practice, Gezira was written and ported several times to multiple different languages. The Gezira algorithms and the stream processor were the important things.</p><p>Gezira would take in a stream of shapes, a pipeline description, and output a stream of pixel colors.</p><p>People like Alan Kay like to promote the idea that we should be chasing "the Maxwell's equations of ___." The Maxwell's equations of rendering would be a short formula, only a couple lines long, which would encompass all of 2D rendering, all edge cases included.</p><p>And so that's what they did.</p><p>Here is their "rendering formula". For a pixel with opposite corners (x, y) and (x+1, y+1), the "coverage" of a single line segment AB is:</p><p>$$\begin{aligned}s(P,Q) & = (Q_y - P_y)(x + 1 - \frac{Q_x + P_x}{2}) \\g(P) & = \min(x+1, \max(x, P_x)), \min(y+1, \max(y, P_y)) \\o(P) & = \frac{1}{m} (g(P)_y - P_y) + P_x, m (g(P)_x - P_x) + P_y \\\text{coverage}(AB) & = s(g(A), g(o(A))) + s(g(o(A)), g(o(B))) + s(g(o(B)), g(B))\end{aligned}$$</p><p>To compute the combined coverage of multiple line segments for a given pixel, you sum them:</p><p>$$\min( | \sum{coverage(AB_i)} | , 1)$$</p><p>This is how it is written on all of Gezira's materials. As far as I can tell, the formula is always presented as-is, and is rarely explained.</p><p>Personally, I think this form is unnecessarily opaque. Here's my version:</p><p>For a line $AB$ and a a pixel with opposite corners (x, y) and (x+1, y+1), the coverage of that line for that pixel is</p><p>$$\begin{aligned}m = & \frac{B_y - A_y}{B_x - A_x} \\\text{trapezoid}(P,Q) = & (Q_y - P_y) \left( x + 1 - \frac{Q_x + P_x}{2} \right) \\\text{snap}(P) = & \min(x+1, \max(x, P_x)), \min(y+1, \max(y, P_y)) \\\text{clip}(P) = & \text{snap} \left( \frac{1}{m} (\text{snap}(P)_y - P_y) + P_x, m (\text{snap}(P)_x - P_x) + P_y \right) \\\text{coverage} = & \text{trapezoid}(\text{snap}(A), \text{clip}(A)) + \\& \text{trapezoid}(\text{clip}(A), \text{clip}(B)) + \\& \text{trapezoid}(\text{clip}(B), \text{snap}(B))\end{aligned}$$</p><p><table><tr style="vertical-align:top"><td width=50%><figure><img src="rendering_formula_simple.svg" style="width:100%"><figcaption>The "coverage" of a line segment for a pixel is the intersection of the area sweeped to the right, and the area of the pixel.</figcaption></figure></td><td><figure><img src="rendering_formula.svg" width="100%"><figcaption>If parts of the line segment lie outside the pixel, the coverage is broken up into pieces and summed together.</figcaption></figure></td></tr></table></p><p><code class="codeinline">trapezoid(P,Q)</code> computes the area of a trapezoid formed by P, Q, and the projections of P and Q on the <i>right edge</i> of the pixel. <code class="codeinline">snap(P)</code> and <code class="codeinline">clip(P)</code> are used to compute which portion of the line is inside the pixel, if any. These are then put together to compute the area of the intersection of the pixel square and the line, if the line were <i>swept right</i>.</p><p>The area is signed as well, thanks to the $(Q_y - P_y)$ term in <code class="codeinline">trapezoid</code>. So if we were computing the total coverage of a closed polygon, any extra coverage for a line segment will get undone by a later line segment that closes the loop.</p><p>The total coverage has that extra $\min( | ... | , 1)$ term to not enforce a particular winding direction, and to handle multiple overlapping shapes.</p><p>This should remind you of other polygon area and winding rule algorithms. Pretty standard technique. It naturally supports the CW/CCW winding rule.</p><p>It does NOT support additional filtering, though since traditional filters are also linear it's not out of the question. It also ONLY supports closed polygons, though it does allow holes by winding them in the opposite direction.</p><p><figure><img src="shutter.svg" style="align-self: center; max-width:100%"><figcaption>A square wave pattern realized with rectangles. It has a frequency of 7/8 = 0.875</figcaption></figure></p><p><figure><img src="alias.svg" style="align-self: center; max-width:100%"><figcaption>Pixel coverage of this pattern as reported by gezira. Note that the 7/8 frequency has aliased to a frequency of 8, and attenuated down to a peak-to-peak amplitude of $145 - 109 = 36 \approx 255 \, \text{sinc}(7/8)$</figcaption></figure></p><p>Why does <code class="codeinline">trapezoid(P,Q)</code> sweep the area out to the right instead of left? I won't get into it now, but it's because Gezira renders scanlines from left to right. If you sort the line segments you can render an entire scanline by updating an accumulator.</p><p>It's important to note that the gezira source code does NOT use the formula as described. For reasons we'll get into later, gezira actually pre-clips line segments. The line segments passed into the coverage computation code are already entirely contained in their given pixel. So there's no need for <code class="codeinline">clip()</code> and <code class="codeinline">snap()</code>.</p><p>The rendering formula that's actually being used looks like:</p><p>$$\text{coverage}(AB) = (B_y - A_y) \left( x + 1 - \frac{Bx + Ax}{2} \right)$$</p><p>So if this rendering formula is supposed to be the basis of all rendering that powers this computing system, how does that work? There's more you might want to render than filled polygons. How does stroking work? Or texturing?</p><p>Stroking works by offsetting the curve in both directions and rendering as a closed shape. More on this later.</p><p>Texturing works by taking a point sample of the texture at the center of a pixel and weighting it by the coverage to blend. More on this later as well.</p><h3 class="section_heading">The demo site</h3><p>The Nile and Gezira source are published <a href="https://github.com/damelang/nile">here</a> and <a href="https://github.com/damelang/gezira">here</a> respectively. From what Dan Amelang has said, it isn't in build-able condition. Significant work will have to be done to get it working <a href="https://github.com/damelang/nile/issues/3#issuecomment-517508949">apparently</a>.</p><p>Luckily, the output from some of the build stages are checked in to the repo, so we can still observe a lot. For example, you can see the gezira's .c files.</p><p>Despite the fact that there's an "official" repo, there seem to be lots of versions of the source out there. It's like every time I see some source listing from this project there's some variation in syntax or data type name or something.</p><ul><li>There's what I'm calling the "official" Gezira source, located in <a href="https://github.com/damelang/gezira/tree/master/nl">this folder</a> in Gezira github repo.</li><li>There's the version written in the comments of the <a href="https://github.com/damelang/gezira/blob/master/hs/gezira.hs">Haskell implementation</a>.</li><li>There's the version in Nile repo, listed <a href="https://github.com/damelang/nile/blob/master/compilers/js/nile-compiler.html">as part of a compiler demo</a>.</li><li>We're going to be looking at a particular demo site that was made for Gezira. That site has yet another version of the source, albiet very similar to the Nile repo version.</li><li>todo: I know there's more]</li></ul><p>There are also several full reimplementations in other languages.</p><p>We're going to be looking at the Gezira source shortly, but I'm torn between which version to show. The "official" source is the most obvious one. When someone wants to see the source code to Gezira they'd go to the gezira repo and look under <code class="codeinline">nl/</code>. </p><p>However, I like the js demo code the most for its stylistic choices. From the file modified dates it also seems like the latest edition. And most importantly, of all of the Gezira versions, this is the only one that <i>actually runs!</i></p><p>Unfortunately, it's not perfect. There are some stylistic changes that were made to get the js demo working. For example, in the "official", source operators get applied elementwise over vectors implicitly, which is nice. I guess they never implemented that in the js demo.</p><p>Whatever. We're going to be looking at the js demo source code. From now on I'm calling this the "latest" source.</p><p>What I'm trying to get at is that this project, though dead and abandonded, is <i>very much</i> a work-in-progress.</p><p>If we're not building it, then what are we doing? Well, the main way I think anyone understands Nile and Gezira these days is from <a href="https://tinlizzie.org/dbjr/high_contrast.html">Bret Victor's demo site</a>.</p><p>Yup! The famous Bret Victor made a little demo site for Gezira in 2012, explorable-explanations style. You can mouse over pixels, beziers, samples, and see how the data flows through the pipeline. You can click the stages to expand and see the sub-stages! Next to each stage is that stage's source code, and as you hover over the elements you see the branches that element took in the source. Very cool!</p><p><figure><img src="bret.png" style="align-self: center; max-width:100%"></figure></p><p>And there's actually more to the site than you see. If you open up the console and paste <code class="codeinline">document.getElementById("mySidebar").style.display="block"; document.getElementById("mySidebar").style.position="relative";</code> you get a menu where you can pick different prepared scenerios.</p><p>This site is a huge help in understanding Gezira.</p><p>The site does have two small, pretty inconsequential bugs: <code class="codeinline">PadGradient</code> should be <code class="codeinline">Real >> Real</code> and not <code class="codeinline">Point >> Point</code>, and <code class="codeinline">Texture</code> should take in <code class="codeinline">SpanCoverage</code> not <code class="codeinline">EdgeSpan</code>.</p><p>It's important to mention that the demo site is NOT interpretting Gezira code. The source listings on the side <i>are</i> Gezira source code, but the interactive stuff is rewritten by hand in javascript. So syntax errors like these don't affect the demo.</p><p>Also, the way that highlighting works on the site can be confusing. The way that <code class="codeinline">CombineEdgeSamples</code> works makes it seem like there's a bunch of off-by-one error, even though there aren't.</p><p>The rest of this post is going to be a breakdown of the Gezira source, specifically the part shown on the demo site. I'll be going through each stage, explaining the code, and giving my thoughts and opinions.</p><h3 class="section_heading">Rasterize</h3><p>Earlier you may have been saying "the rendering formulas are nice, but they're only for line segments? What about curves? They're pretty important for 2D rendering." And you'd be right.</p><p>Gezira actually operates exclusively on beziers, which it then deconstructs into line segments at the last moment. Surprisingly, it uses <i>quadratic</i> beziers instead of cubic. This is presumably because due to the focus on text, and because TrueType only supports quadratic beziers?</p><p>(Interestingly, in <a href="https://www.youtube.com/watch?v=HAT4iewOHDs&t=1025s">this talk</a> given by Dan Amelang, he explicitly says that the beziers are cubic. However <i>none</i> of the versions of the gezira source I've seen support cubic beziers.)</p><p>The first major stage of rasterization takes in a stream of quadratic beziers and output <code class="codeinline">CoverageSpan</code>s.</p><pre class="codeblock"><code>Rasterize () : Bezier >> SpanCoverage
    → DecomposeBeziers () → SortBy (1) → SortBy (2) → CombineEdgeSamples ()
</code></pre><p>The pipeline here is self-explanatory.</p><p>There's actually a difference here between the "latest" source and the "official" source. The "official" source lists this:</p><pre class="codeblock"><code>Rasterize : Bezier >> CoverageSpan
    ⇒ DecomposeBeziers → SortBy (@x) → SortBy (@y) → CombineEdgeSamples
</code></pre><p>The eagle-eyed might notice two different operators here: <code class="codeinline">⇒</code> and <code class="codeinline">→</code>. In my editor they look <i>very</i> similar. The <code class="codeinline">⇒</code> operator seemed to be used when beginning a new pipeline, and <code class="codeinline">→</code> continued it. I'm glad this was changed.</p><p>The other differences aren't important. In the "official" source <code class="codeinline">DecomposeBeziers</code> and <code class="codeinline">CombineEdgeSamples</code> don't have parameter lists, but that's just a syntax change.</p><p>Like I've mentioned already, the source listed on the demo site actually comes from Nile js compiler demo. So the source listed here is mostly the same, but sometimes won't match up exactly with the demo site.</p><h3 class="section_heading">DecomposeBeziers</h3><p>Anyways, here's the first stage:</p><pre class="codeblock"><code>type EdgeSample    = (x:Number, y:Number, area:Number, height:Number)

DecomposeBeziers () : Bezier >> EdgeSample
    ϵ = 0.1
    ∀ (A, B, C)
        P = ⌊A⌋ ◁ ⌊C⌋
        if ∧(P ≤ A ≤ P + 1 ∧ P ≤ C ≤ P + 1)
            (x, y) = P
            (w, _) = P + 1 - (A ~ C)
            (_, h) = C - A
            >> (x + 0.5, y + 0.5, wh, h)
        else
            M            = (A ~ B) ~ (B ~ C)
            ( min,  max) = (⌊M⌋, ⌈M⌉)
            (Δmin, Δmax) = (M - min, M - max)
            N = { min, if |Δmin| < ϵ
                  max, if |Δmax| < ϵ
                    M,     otherwise }
            << (N, B ~ C, C) << (A, A ~ B, N) 
</code></pre><p>This step does a lot of work. It takes each bezier, recursively breaks it apart into smaller beziers until it's "small enough" and fits inside a single pixel square, then applies the simplified rendering formula from above, to finally output the contribution of THAT bezier piece in THAT pixel.</p><p>Let's take it a bit at a time.</p><p>It first tests whether the bezier is fully contained in a single pixel by checking its two endpoints. There's an obvious problem with this, but I'll get to that later.</p><p>The formula it uses for this is:</p><pre class="codeblock"><code>P = ⌊A⌋ ◁ ⌊C⌋
if ∧(P ≤ A ≤ P + 1 ∧ P ≤ C ≤ P + 1)
  ...
</code></pre><p>Being a streaming language, gezira takes after APL. So we're going to be seeing lots of funny symbols everywhere. Maxwell's equations and all that.</p><p><code class="codeinline">floor</code> and <code class="codeinline">ceil</code> are very common and useful in graphics, so they're given their own operators. In nile, these operators are applied elementwise.</p><p>We also see the <code class="codeinline">and</code> operator, <code class="codeinline">∧</code>, being applied once elementwise <code class="codeinline">(Bool², Bool²) >> Bool²</code>, and then again across elements <code class="codeinline">Bool² >> Bool</code>.</p><p>The <code class="codeinline">◁</code> operator computes the min of two numbers. It was chosen because it kinda looks like a <code class="codeinline"><</code> sign. Similarly the <code class="codeinline">▷</code> operator computes max. Because min is commutative, it's envisioned here as an infix operator. So you can chain them together like <code class="codeinline">A ◁ B ◁ C</code>! Same with max.</p><p>And actually, min and max associate (but don't commute) with each other. So statements like <code class="codeinline">min ▷ A ◁ max</code> make sense. This is used to clamp numbers in a couple places in gezira. Very cool! This is a nice demonstration of the STEPS conceit. [todo: have i mentioned STEPS yet?]</p><p>This is slightly different from the source on the demo site:</p><pre class="codeblock"><code>inside = (⌊ A ⌋ = ⌊ C ⌋ ∨ ⌈ A ⌉ = ⌈ C ⌉)
if inside.x ∧ inside.y
</code></pre><p>This isn't used in the "latest" source because it has a small bug:</p><p><figure><img src="pixel_inclusion.svg" style="align-self: center; max-width:100%"></figure></p><p>In the image above, example line segments 1, 5, 6, and 7 are entirely contained in a pixel boundary. Number 6 looks wrong because, while it's not contained in the blue pixel square, it is entirely contained in the <i>next pixel to the right</i>. Remember, in this stage pixels aren't asking which beziers they contain. The beziers themselves are asking if they are contained inside of a pixel.</p><p>It's an elegant formulation, and handles the case where one of the endpoints lie on a pixel boundary. If they do that, they'll have integer coordinates, and so <code class="codeinline">⌊A⌋ = ⌈A⌉</code>. See image above.</p><p>This works nicely in all cases but one: the case where the endpoints lie on opposite edges of a pixel square. This is the example number 7 above.</p><p>This is actually <a href="https://github.com/damelang/gezira/blob/9f3e6846f4a1732c344a3b99e5d670deac618b17/TODO#L37">mentioned in one of the TODO files</a> in the gezira git repo.</p><pre class="codeblock"><code>    - optimization: how often do we get tiny beziers with
      endpoints on opposite sides of the pixel square? We currently split
      these, but could try not doing it (with effects on visual quality)
</code></pre><p>The "latest" source fixes this by directly calculating the box that the bezier should be in.</p><p>I liked the old version though! It was simple and clever. So here's a version I came up with that preserves the spirit of the  old version:</p><pre class="codeblock"><code>if ∧(⌈A⌉ - 1 <= B <= ⌊A⌋ + 1)
  ...
</code></pre><p><figure><img src="pixel_inclusion_corrected.svg" style="align-self: center; max-width:100%"></figure></p><p>Anyways, let's tackle the else branch next.</p><pre class="codeblock"><code>M            = (A ~ B) ~ (B ~ C)
</code></pre><p>Again, cool use of a DSL. The <code class="codeinline">~</code> operator calculates <code class="codeinline">(A + B)/2</code>. This one is used all the time. Here, the beziers are always split at the t=0.5 point.</p><pre class="codeblock"><code>( min,  max) = (⌊M⌋, ⌈M⌉)
(Δmin, Δmax) = (M - min, M - max)
N = { min, if |Δmin| < ϵ
      max, if |Δmax| < ϵ
        M,     otherwise }
</code></pre><p>This is a little messy. See, if you always split beziers at the midpoint, there are too many situations where this will recurse forever, generating smaller and smaller beziers that cross pixel boundaries. So you need to clamp the endpoints when they get "close enough."</p><p>Note that even the inline <code class="codeinline">if</code> statement is being computed element-wise! <code class="codeinline">|Δmin|</code> and <code class="codeinline">|Δmax|</code> are both computing absolute values elementwise. To compute a vector norm, you'd have to do <code class="codeinline">‖ A ‖</code>, with the double bars. I suppose not even Nile and Gezira can get away from these sorts of problems.</p><p>There's actually another function in the Gezira source which seems to do something very similar, <code class="codeinline">ClipBeziers</code>, which is never used.</p><p>Note here also the unicode characters in the variable names Δmin and Δmax. Also, <code class="codeinline">|x|</code>, and most other operators you see in the source are user-defined. They're all defined at the top of the source.</p><pre class="codeblock"><code>a:Number² : Number
    aa

a:Number³ : Number
    aaa

|a:Number| : Number
    { -a, if a < 0
       a, otherwise }

a:Number ≈ b:Number : Boolean
    |(a - b)| < 0.0001
...
</code></pre><p>The gezira syntax seems incredible and expressive, but the syntax is more restrictive than it looks.</p><p>While it's true that you can use non-latin characters in your variable names, those non-latin characters can ONLY be from the greek/coptic unicode block U+0370 - U+03FF. And operators CAN'T be latin characters or greek/coptic characters. For example, if you wanted to define an operator <code class="codeinline">Δf(x)</code> to be defined as <code class="codeinline">f(x+1) - f(x)</code> or <code class="codeinline">∇ ∙ ∇</code> or whatever, it couldn't exist at the same time as a variable named <code class="codeinline">Δmin</code>, even if you changed the grammar.</p><p>That's because OMeta, the parser used to parse gezira code, doesn't include a symbol table as part of its grammar. So it can't backtrack on "this variable/operator name isn't bound."</p><p>The opposite problem, where the syntax is too unrestricted, happens with the <code class="codeinline">|x|</code> operator. If above <code class="codeinline">|Δmin|</code> had been written as the equivalent <code class="codeinline">|M - min|</code>, it would cause a compile error. The gezira grammar parses <code class="codeinline">|M - min|</code> as <code class="codeinline">(|M) - (min|)</code>, where <code class="codeinline">|</code> is interpreted as a prefix operator in the first and a postfix operator in the second.</p><p>I'm not so sure how fundamental this second problem is. It seems to me that outfix operators should always take precedence over infix, like parenthesis. I'm not a PLT guy, so maybe there's some reason why that can't be made to work.</p><pre class="codeblock"><code><< (N, B ~ C, C) << (A, A ~ B, N) 
</code></pre><p>This then recurses twice, once for each bezier half.</p><p>As I've said, Nile is a stream processing language. It takes in an input stream and outputs an output stream. The <code class="codeinline">∀</code> block will run until the input stream is empty.</p><p>Nile supports recursion by pushing values <i>back onto the head of the input stream</i>. In this case, after this line runs and the <code class="codeinline">∀</code> loops again, <code class="codeinline">(A, A ~ B, N)</code> will get processed instead of whatever was next.</p><p>Now for the <code class="codeinline">if</code> branch.</p><pre class="codeblock"><code>(x, y) = P
(w, _) = P + 1 - (A ~ C)
(_, h) = C - A
>> (x + 0.5, y + 0.5, wh, h)
</code></pre><p>This is just the simplified rendering equation from above. The beziers, now hopefully small, are treated as if they're line segments for the purposes of rendering.</p><p>In addition to this bezier's resident pixel, other pixels in its scanline will need to know how much this bezier contributes to <i>them</i>. This is the 4th parameter of <code class="codeinline">EdgeSample</code>.</p><p>We see that the pixel coordinates are chosen to be 0.5 offset.</p><p>Multiplication happens by just concatenating variables. I don't know how I feel about that.</p><p>In the "official" source, the <code class="codeinline">×</code> operator is used for multiplication. I <i>do</i> know how I feel about that. Not a fan. I admire his commitment to the bit, though!</p><h4>Thoughts</h3><p>The <code class="codeinline">∧(P ≤ A ≤ P + 1 ∧ P ≤ C ≤ P + 1)</code> test is not great. Unlike the other approximation, this one can be arbitratily wrong.</p><p><figure><img src="bezier_problem.svg" style="align-self: center; max-width:100%"></figure></p><p>In this picture we have a bezier whose two endpoints are inside a single pixel, but whose peak extends outside. Because the endpoints are horizontal, the algorithm as described will NOT split, and will compute a coverage of 0 for this bezier. In actuality it should be close to 1, and furthermore the pixel above should be seeing some additional coverage as well.</p><p>We're trying to measure the coverage of a bezier, but we only have the formula for the coverage of a line segment. We're trying to find a good time to stop subdividing, which happens when the coverage of the bezier is approximately equal to the coverage of the line segment.</p><p>The fundamental problem is that gezira's algorithm tries to determine when the coverages are close enough by measuring <i>length</i>. We need to measure <i>area</i> instead.</p><p>I propose instead measuring the area of the triangle <code class="codeinline">ABC</code>, formed by the two endpoints and the handle. Stop subdividing when the area goes under <code class="codeinline">ϵ</code>.</p><p>This metric is good for two reasons:</p><p>First, this metric makes constant geometric forward progress. If the triangle represented by the bezier <code class="codeinline">ABC</code> gets subdivided, both triangles of the sub-beziers <code class="codeinline">A(A~B)M</code> and <code class="codeinline">M(B~C)C</code> will measure exactly 1/8th the area of the original triangle <code class="codeinline">ABC</code>.</p><p>Second, it directly measures what you're looking for. The smaller the are of the triangle <code class="codeinline">ABC</code>, the more colinear the points are, and the straighter the bezier. Also, the internal area of a bezier <code class="codeinline">ABC</code> is directly proportional to the area of the triangle <code class="codeinline">ABC</code>, with a ratio of 2/3. So this metric is directly measuring the coverage error per bezier.</p><p>Unfortunately there are no cross products or wedge products or determinants already implemented in the gezira source, so this looks a bit messy. It might look something like this:</p><pre class="codeblock"><code>DecomposeBeziers () : Bezier >> EdgeSample
  ϵ2 = 0.5
  ∀ (A, B, C)
    (a, b) = B - A
    (c, d) = C - A
    if ∧(⌈A⌉ - 1 <= B <= ⌊A⌋ + 1) ∧ (|(ad - bc)| < ϵ2)
      ...
</code></pre><p>And actually, I think the endpoint clamping can be made better too.</p><p>Since I'm already talking about approximating beziers with lines, how about cementing this idea? Turn <code class="codeinline">DecomposeBeziers</code> into a function <code class="codeinline">Bezier >> Line</code>, and then have another function that goes <code class="codeinline">Line >> EdgeSample</code>.</p><p>Maybe something like this:</p><pre class="codeblock"><code>type Line = (A:Point, B:Point)

DecomposeBeziers () : Bezier >> Line
  ϵ = 0.5
  ∀ (A, B, C)
    (a, b) = B - A
    (c, d) = C - A
    if |(ad - bc)| < ϵ
      >> (A, C)
    else
      M = (A ~ B) ~ (B ~ C)
      << (M, B ~ C, C) << (A, A ~ B, M)

GenerateEdgeSamples () : Line >> EdgeSample
  ∀ (A, B)
    (w, h) = B - A
    (insidex, insidey) = (⌈A⌉ - 1 ≤ B ≤ ⌊A⌋ + 1)
    if insidex ∧ insidey
      P = ⌊A⌋ ◁ ⌊B⌋
      (x, y) = P
      (g, _) = P + 1 - (A ~ B)
      >> (x + 0.5, y + 0.5, gh, h)
    else
      (Ax, Ay) = A
      (midx, midy) = ⌊((A ~ B) + 0.5)⌋
      M = { (midx, (midx - Ax) h / w + Ay), if insidey
            ((midy - Ay) w / h + Ax, midy), otherwise }
      << (A, M) << (M, B)
</code></pre><p>That's 9 additional lines in exchange for some subjective consistency. The rendering formula that is supposedly the basis for this software is expressed in terms of lines. Here's a function that computes the coverage of lines. The "rendering formula" defines <code class="codeinline">snap</code> and <code class="codeinline">clip</code>, and now the code implements something similar.</p><p>There's also the problem of introducing a new concept, Line. But you could fix that by removing the pointless distinction between <code class="codeinline">Point</code> and <code class="codeinline">Vector</code>.</p><p>The other idea that keeps with the <i>spirit</i> of the original source is to subdivide each bezier by the pixel boundaries, instead of at t=0.5. This caps the maximum coverage error per initial bezier at 0.666 per pixel intersected. It's easy too, since quadratic beziers are just parabolas. It does take more code, though. Enough that you'd probably want to add a new quadratic equation operator.</p><h3 class="section_heading">Sort</h3><p>We want to compute pixel coverages for all pixels in a scanline, but we only have coverage information about the edges in their resident pixel. So some kind of prefix sum or integral or whatever is unavoidable. If we want to do this prefix sum without touching pixels multiple times, the data has to be sorted.</p><p>This step sorts the <code class="codeinline">EdgeSample</code>s into scanline order. There will often be multiple <code class="codeinline">EdgeSample</code>s per pixel, but also large gaps between pixels with no <code class="codeinline">EdgeSample</code>s.</p><p>I'll save my commentary about this for the next section.</p><h3 class="section_heading">CombineEdgeSamples</h3><pre class="codeblock"><code>type SpanCoverage  = (x:Number, y:Number, coverage:Number, length:Number)

CombineEdgeSamples () : EdgeSample >> SpanCoverage
    (x, y, A, H) = (0, 0, 0, 0)
    ∀ (x', y', a, h)
        if y' = y
            if x' = x
                (A', H') = (A + a, H + h)
            else
                (A', H') = (H + a, H + h)
                >> (x,     y, |A| ◁ 1,          1)
                >> (x + 1, y, |H| ◁ 1, x' - x - 1)
        else
            (A', H') = (a, h)
            >> (x, y, |A| ◁ 1, 1)
    >> (x, y, |A| ◁ 1, 1)
</code></pre><p>At this point some <code class="codeinline">EdgeSample</code>s might occupy the same pixel, and some interior pixels will have no coverage computed for them.</p><p>This one will merge <code class="codeinline">EdgeSample</code>s that lie in the same pixel, and will also group together "spans" of interior pixels. These interior "spans" will have coverage 0.0 or 1.0, unless I guess your shape isn't closed? But then again, this whole algorithm won't work if the shape isn't closed.</p><pre class="codeblock"><code>(x, y, A, H) = (0, 0, 0, 0)
</code></pre><p>Usually you'd start these sorts of loops with a <code class="codeinline">x = min(edge sample xs)</code> or something. But since all <code class="codeinline">x</code>s and <code class="codeinline">y</code>s are always at 0.5 offsets, setting <code class="codeinline">x = 0</code> works.</p><pre class="codeblock"><code>∀ (x', y', a, h)
  ...
>> (x, y, |A| ◁ 1, 1)
</code></pre><p>You can see here that <code class="codeinline">∀</code> is a general looping keyword. In the previous examples, <code class="codeinline">∀</code> could have maybe meant <code class="codeinline">map</code> or <code class="codeinline">map | flatten</code> or something. But here it pretty explicitly means <code class="codeinline">for</code>. There's a prologue and epilogue to the loop, and the loop is meant to run sequentially.</p><pre class="codeblock"><code>if y' = y
    if x' = x
        (A', H') = (A + a, H + h)
    else
        (A', H') = (H + a, H + h)
        >> (x,     y, |A| ◁ 1,          1)
        >> (x + 1, y, |H| ◁ 1, x' - x - 1)
else
    (A', H') = (a, h)
    >> (x, y, |A| ◁ 1, 1)
</code></pre><p>This loop body will run in scanline order, thanks to the <code class="codeinline">SortBy</code>s last stage.</p><p>Same <code class="codeinline">x</code> coordinates accumulate coverage. New <code class="codeinline">x</code> coordinates output twice, once for the old accumulator and once for the span between the old <code class="codeinline">x</code> and new <code class="codeinline">x</code> (which can have 0 length). New <code class="codeinline">y</code> coordinates mark the end of a scanline, so output and reset state.</p><p>This is just a prefix sum over each scanline.</p><p>At the end of this loop, every pixel inside or on the border of the shape will be covered by one SpanCoverage.</p><p>You might notice that the variables <code class="codeinline">A</code> and <code class="codeinline">H</code> aren't being set. In Nile, variables are all immutable. To update variables in a loop, Nile uses the special syntax of appending a <code class="codeinline">'</code> to it, like in <code class="codeinline">(A', H') = (a, h)</code>.</p><h4>Thoughts</h3><p>I'm not very familiar with this sort of 2D rendering, so I did a little bit of reading on the subject. </p><p>It turns out that this general algorithm, breaking apart curves, sorting, and prefix summing, is actuall pretty common. There are CPU implementations, GPU implementations. This general algorithm is being used to render lots of very big serious projects like Google Maps and <a href="https://wiki.openstreetmap.org/wiki/Mapnik">OpenStreetMap</a> and the major browsers. [todo: google maps link]</p><p>This technique wasn't new when Dan Amelang was writing gezira. The earliest example of this algorithm I know of is from AntiGrain Geometry in 2005. I'm certain that there are much earlier examples of this algorithm. [todo: this link https://cairo.cairographics.narkive.com/mkJB7CJ7/anti-grain-geometry-yet-another-2d-rendering-library makes it seem like cairo used this algo even earlier?]</p><p>And man, this stuff gets intense. I'm not qualified to talk about what could be improved about gezira, or what lessons the 2D rendering community has learned in the intervening years. I'll instead talk very broadly.</p><p>There is only one instance of <code class="codeinline">SortBy</code> in the gezira source. This isn't necessarily a bad thing, it just gives me pause. All other parts of the rendering algorithm are pretty trivially parallelizable. I just think that an algorithm that requires less sorting would be good.</p><p>Dan Amelang talks about this on this message on the VPRI mailing list. Though, his concerns are a little dated. In the 15 years since, GPGPU programming has made many of his concerns moot.</p><p>Personally, but I think that triangles would make things easier. Triangles are a more direct measure of coverage than curves. With triangles there's no need to do an integral across scanlines. Each one contains its own boundary information.</p><p>I can understand why the decision was made to go with curves, but it's probably not the one I would have gone with. I think triangles are more in line with the mission. For me, a big part of low-LOC and "reinventing computing" for "simplicity" is choosing good primitives. A good primitive is one whose essence answers the question being asked. You're trying to measure area. The most fundamental structure that embodies area is the rectangle. Rectangles have some issues when they're not axis-aligned, so the next best is the triangle.</p><p>Some of the usual issues with triangles, like issues with small triangles and shared edges, aren't a problem in gezira. You just render them together like it's doing now, and the coverage will always come out correct.</p><p>This curve vs triangle critique isn't a big deal. There are problems involved that I don't know how to solve. I just think that triangle binning is better than sorting and integrating.</p><p>Part of the conceit of DSLs, from a low-LOC point of view, is similar to that of optimizing compilers. You can match patterns in the source code and replace them with larger optimized versions. In terms of LOC, it converts a <code class="codeinline">A*B</code> problem into <code class="codeinline">A+B</code>.</p><p>I bring this up because the <code class="codeinline">sum = 0; ∀ x; sum' = x</code> pattern is only used three times in gezira. Once in <code class="codeinline">CalculateBounds</code>, which just does a running min/max. Once in <code class="codeinline">SumWeightedColors</code> to downsample and filter. And once in <code class="codeinline">CombineEdgeSamples</code>, summing coverage in scanlines.</p><p>(Unrelated, but <code class="codeinline">CalculateBounds</code> is weird. I have no idea why it's written to ignore horizontal lines.)</p><p>Nile currently doesn't attempt to do any sort of optimization for this. Multithreading is supported in the C runtime, but it's only pipeline level parallelism. OpenCL ports were planned but never implemented.</p><p>Simple pattern matchers live and die on the richness of the source. If the source code can express more intent, the compiler can be much simpler. Nile currently detects this scenerio by looking for <code class="codeinline">'</code> symbols on variables.</p><p>Dan Amelang has said that the desired parallelism model is both parallelism across elements of a stream AND across pipeline stages.</p><p>However, to parallelize a prefix sum you need to isolate the parts of your calculation that are associative. That simply can't happen with the current syntax. You need to be explicit about this.</p><p>This is actually mentioned by Dan Amelang in <a href="https://fonc.vpri.narkive.com/rtIMYQdk/nile-gezira-was-re-1-ftw">this email</a> in the VPRI mailing list:</p><p>I suggest ditching the <code class="codeinline">∀</code> keyword on these 3 functions and replacing them with another primitive, one that means "prefix sum".</p><p>Just spitballing here, maybe an operator <code class="codeinline">∫</code> that takes in an initial value, a variable to bind the "previous" value to, a variable to bind the "current" value to, and a loop body. This loop will bind "current" to the top of the input stream, and "previous" to the <i>bottom of the output stream</i> (in other words, the last value that was output). You can <code class="codeinline">>></code> zero, one, or two values on any given loop iteration. If you <code class="codeinline">>></code> two values, it will replace the value at the bottom of the output stream with the first, and then push the second. If you <code class="codeinline">>></code> only one value, it will just replace the bottom of the output stream. The loop body, expressed as <code class="codeinline">(previous, current) -> (_, new_previous)</code> is required to be associative.</p><p>The <code class="codeinline">∀</code> operator is able to implement <code class="codeinline">map</code>, <code class="codeinline">filter</code>, as well as certain limited <code class="codeinline">foldr</code> applications. The <code class="codeinline">∫</code> operator just described is able to implement <code class="codeinline">reduce</code>, <code class="codeinline">prefix sum</code>, as well as certain limited <code class="codeinline">foldl</code> operations.</p><pre class="codeblock"><code>CalculateMinBounds () : Bezier >> Point
  ∫ ∞ min (A, B, C)
    >> min ◁ A ◁ B ◁ C

CombineEdgeSamples () : EdgeSample >> SpanCoverage
    ∫ (0, 0, 0, 0, 0) (cx cy ca ch chh cl) (x y a h)
      if y = cy
        if x = cx
          >> (x, y, a + ca, h + ch, chh, cl)
        else
          >> (cx cy ca ch chh cl)
          >> (x, y, a, h, ch, x - cx - 1)
      else
        >> (cx cy ca ch chh cl)
        >> (x, y, a, h, 0, 0)
</code></pre><h3 class="section_heading">ApplyTexturer</h3><p>Texturing is meant to happen directly after <code class="codeinline">Rasterize</code>. In fact <code class="codeinline">ApplyTexturer</code> and <code class="codeinline">ExpandSpans</code> are the only functions in gezira that can take in <code class="codeinline">SpanCoverage</code> as input.</p><pre class="codeblock"><code>ApplyTexturer (t:Texturer) : SpanCoverage >> (Color, PointCoverage)
    → ExpandSpans () → DupZip (→ ExtractSamplePoints () → t,
                               → PassThrough ())
</code></pre><p>Pretty straightforward. <code class="codeinline">SpanCoverage</code>s get destructed, and then passed to a "texturer", which ends up binding pixel position, coverage, and color together.</p><p>A <code class="codeinline">Texturer</code> is just an alias of <code class="codeinline">Point >> Color</code>. So a pretty standard fragment-shader-like setup.</p><p><code class="codeinline">PassThrough</code> is a special built-in function, it's just the identity function. Its output stream is the same as its input stream. It is sometimes written with the special syntax <code class="codeinline">(→)</code>. It's not used much.</p><p>The version listed on the demo site is similar. Instead of passing in a <code class="codeinline">Texturer</code> the pipeline is just hardcoded. In the "latest" source there are a couple functions that do the work of making the texturing pipeline for you.</p><h3 class="section_heading">Gradients</h3><p>All preprogrammed "textures" in Gezira are gradients. Linear and radial are your two options.</p><p>There's no reason why this has to be the case, it's just e.g. bitmapped texture functionality isn't present in the Gezira source. All that's required is the ability to do single point lookups. So texture UV coordinates would have to be carried in a parallel stream during rasterization.</p><pre class="codeblock"><code>ProjectLinearGradient (A:Point, B:Point) : Point >> Number
    v   = B - A
    Δs  = v / (v ∙ v)
    s00 = A ∙ Δs
    ∀ P
        >> P ∙ Δs - s00
</code></pre><p>This function shows off how parameters work in Nile. They're a way to pass in values that are constant for the entire input stream.</p><p>In the demo source, this is typed as <code class="codeinline">PointCoverage >> Real</code>, to make the pipeline easier.</p><p>In the "official" source, this function is called just <code class="codeinline">LinearGradient</code>. I don't know where the "Project" part came from.</p><p>Not much more to say about this one. Nice and succinct.</p><pre class="codeblock"><code>PadGradient () : Real >> Real
    ∀ s
        >> 0 ▷ s ◁ 1
</code></pre><p>Here's that clamping syntax I was talking about!</p><p>On the demo page, the source listing is wrong. It should be typed <code class="codeinline">Real >> Real</code>. Transcription error?</p><p>I also don't know why this is called "padding" a gradient. But this terminology is also used in SVG, so what do I know?</p><p>This one is split off from <code class="codeinline">LinearGradient</code> because, in the source, there are 2 other gradient manipulation functions: <code class="codeinline">RepeatGradient</code> and <code class="codeinline">ReflectGradient</code>. <code class="codeinline">PadGradient</code> is meant to be useful for both <code class="codeinline">LinearGradient</code> and <code class="codeinline">RadialGradient</code>. I don't know what situation you'd ever want your linear gradient to go outside of [0,1], but whatever.</p><p>Funnily, there's also a <code class="codeinline">PadTexture</code>, <code class="codeinline">RepeatTexture</code>, and <code class="codeinline">ReflectTexture</code> in the full source. These could be used instead. You can manipulate the incoming <code class="codeinline">Point</code> as opposed to manipulating the outgoing Real. That would have saved 10 lines.</p><pre class="codeblock"><code>GradientSpan (A:Color, a:Number, B:Color, b:Number) : (Number, Color) >> (Number, Color)
    ∀ (s, C)
        α = (b - s) / (b - a)
        D = { αA + (1 - α)B, if a ≤ s ≤ b
              C,             otherwise    }
        >> (s, D)
</code></pre><p>In the demo source, this is written a bit different:</p><pre class="codeblock"><code>GradientSpan (A:Color, B:Color) : Real >> Color
  ∀ s
    >> sA + (1 - s)B
</code></pre><p>Not sure why that was changed. In any event, this one is pretty simple too.</p><pre class="codeblock"><code>ZipPixels () : (PointCoverage, Color) >> Pixel
  ∀ ((x, y, coverage), (r, g, b, a))
    >> ((x, y), (r, g, b, a * coverage))
</code></pre><p>This one is listed on the demo site but isn't present in the "latest" source. I'm showing this one because the rest of the source also uses premultiplied alpha. Functions for doing the final composite <a href="https://github.com/damelang/gezira/blob/9f3e6846f4a1732c344a3b99e5d670deac618b17/TODO#L54">were planned</a>, but never written. I gather there's supposed to be some user-provided special code to do the final composite and get rid of the alphas?</p><h3 class="section_heading">Stroke</h3><p>Stroking is done by offsetting a curve in both directions, capping the ends, and then using the rendering functions above to render the stroke as a solid shape.</p><p>When I first looked into gezira, I thought the choice of beziers as the drawing primitive was a little odd. Stroking is one of gezira's main features, and it's well-known that the offset shape of a quadratic bezier is NOT a quadratic bezier.</p><p>But that's actually not a problem. The <code class="codeinline">OffsetBezier</code> function will first subdivide the shape into piecewise nearly linear pieces before stroking.</p><p>After learning that, I thought "ah, I see. Beziers are chosen as the base primitive because they come with tangent information at the ends. This makes stroking easier, since there's no need to join connected curves, which would be hard using this streaming language."</p><p>But no, it does join connected curves. This is interesting because to join curves you need to look at <i>pairs</i> of connected curves to get the angle right.</p><p><figure><img src="stroke.svg" style="align-self: center; max-width:100%"><figcaption>A stroked bezier with round caps and mitered joins. The red curve is the original curve. The green is the stroke outline. The black interior fill is what the normal gezira winding order fill looks like.</figcaption></figure></p><p>Note the self-intersected geometry in the "elbow" of this curve. This doesn't affect the visual look of the filled curve. That's because the winding direction of the self-intersection is the same as the winding order of the rest of the stroke geometry. I think this is fine, and not a big deal.</p><p>The functions we've looked at so far operate on one item at a time, so we're about to see something different.</p><p>Before I continue, it's important to note that the hidden stroke demo on Bret Victor's demo site doesn't do anything even close to what the source on in the sidebar is claiming that it does. There's no hope trying to read the page source to figure it out.</p><p>Stroking works by duplicating the input stream, stroking one side of the path, reversing, and then stroking the other.</p><pre class="codeblock"><code>StrokeBezierPath (width:Number, limit:Number, cap:Number) : Bezier >> Bezier
    → SanitizeBezierPath () →
      DupCat (→ StrokeOneSide (width, limit, cap),
              → Reverse () → ReverseBeziers () → StrokeOneSide (width, limit, cap))
</code></pre><p><code class="codeinline">DupCat</code> and <code class="codeinline">Reverse</code> here are built-in. They does what they say on the tin. Notice that <code class="codeinline">DupCat</code> takes pipelines as arguments.</p><p><code class="codeinline">StrokeOneSide</code> always strokes the left side of a curve (in the normal x-right y-up coordinate system), and on non-closed curves always caps the final curve. Reversing and stroking creates a full closed shape that can be passed to <code class="codeinline">Rasterize</code>. The closed path comes out in the right order too, with a caveat that I'll mention later.</p><p>I won't list <code class="codeinline">SanitizeBezierPath</code>. It just checks if the control point is roughly colinear with the endpoints, and if so replaces the bezier with one or more that are less pathological.</p><p><code class="codeinline">ReverseBeziers</code> also does what it says on the tin. I won't list that either.</p><h4>StrokeOneSide</h3><p><code class="codeinline">StrokeOneSide</code> is where it gets weird.</p><pre class="codeblock"><code>OffsetAndJoin (Zi:Bezier, Z1:Bezier, o:Number, l:Number, c:Number) : Bezier >> Bezier
    ∀ Zj
        → OffsetAndJoin (Zj, Z1, o, l, c) →
          JoinBeziers   (Zi, Zj, o, l)    → OffsetBezier (Zi, o)
    if Zi.C = Z1.A
        → JoinBeziers (Zi, Z1, o, l) → OffsetBezier (Zi, o)
    else
        → CapBezier (Zi, o, c)       → OffsetBezier (Zi, o)

StrokeOneSide (width:Number, limit:Number, cap:Number) : Bezier >> Bezier
    ∀ Z1
        → OffsetAndJoin (Z1, Z1, width / 2, limit, cap)
</code></pre><p>The <code class="codeinline">width</code> parameter is the width of the stroke, obviously. <code class="codeinline">limit</code> is the miter limit, which can be set negative to choose round joins. <code class="codeinline">cap</code> is set positive or negative to choose between rounded or square caps.</p><p>If you squint at it, you can see the shape of the pipeline. <code class="codeinline">JoinBeziers</code> emits geometry to join two beziers. <code class="codeinline">OffsetBezier</code> offsets beziers to the left. And there's some kind of recursion going on. Then at the end, either <code class="codeinline">CapBezier</code> the last curve or <code class="codeinline">JoinBeziers</code> the first and last curve.</p><p>But the closer you look at it, the more confusing it is, I think. The new syntax of <code class="codeinline">∀ x; → Self (x)</code> is very non-obvious in its mechanics. The switch from <code class="codeinline"><<</code> style recursion to this more traditional style is also confusing.</p><p>Since this snippet is a bit noisy, here's a simplified version of this pattern:</p><pre class="codeblock"><code>Stage3 (a: Number, b: Number) : Number >> Number
  t = 10
  >> (ta + b)

Stage2 (a: Number) : Number >> Number
  ∀ b
    → Stage2 (b) → Stage3 (a, b)

Stage1 () : Number >> Number
  ∀ a
    → Stage2 (a)
</code></pre><p>You do this weird double <code class="codeinline">∀</code> thing across two different stages, where the second stage starts with a recursion. Then stage 3 gets adjacent pairs as arguments that you can do what you want with!</p><p>Here, feeding the stream <code class="codeinline">(1, 2, 3, 4, 5, 6, 7, 8, 9)</code> into the pipeline <code class="codeinline">→ Stage1 ()</code> gives back the stream <code class="codeinline">(12, 23, 34, 45, 56, 67, 78, 89)</code>, as expected.</p><p>So what's the deal with this new syntax? It seems like a weird hack that depends on the specific way that streams in Nile work. Nile's pseudocode might look something like this:</p><pre class="codeblock"><code>handle_function(env, proc) {
  // Handle loop prologue.
  // This is where pipeline statements would normally go.

  // Handle loop.
  while (env.input_stream.non_empty()) {
    input = env.input_stream.consume();
    
    // Evaluate/deconstruct/whatever the input, bind it to the loop variable, add it to the env's symbol table.
    bind(env, proc.loop.vars, input);
    
    // Do whatever the loop body says.
    // Normally that involves pushing onto the output_stream or back onto the top of the input_stream.
    // Any pipeline statements are run, with the current input_stream.
    eval(env, proc.loop.body);
  }
  
  // Handle loop epilogue.
}
</code></pre><p>There are 3 weird things that go into this.</p><p>First, the loop <code class="codeinline">∀ x; → StageN ()</code> will consume one item from the input stream before running <code class="codeinline">StageN</code>. This means that <code class="codeinline">StageN</code> will see one less item than <code class="codeinline">StageN-1</code>. So if <code class="codeinline">Stage1</code> gets run on the input stream <code class="codeinline">(1, 2, 3, 4)</code>, <code class="codeinline">Stage2</code> will get run with <code class="codeinline">(2, 3, 4)</code>.</p><p>Second, <code class="codeinline">∀ x; → StageN ()</code> will break after <code class="codeinline">StageN</code> runs. This is because a pipeline will link its input and output stream to its parent function's streams. <code class="codeinline">StageN</code> will run with whatever is left in its parent's input stream. And after it returns, its parent's input stream will be empty, so the <code class="codeinline">∀</code> will only loop once.</p><p>The end result is that the <code class="codeinline">∀ x; → StageN ()</code> pattern has the effect of removing the top item from the input stream before running <code class="codeinline">StageN</code>.</p><p>You may have noticed that <code class="codeinline">Stage2</code> is written as <code class="codeinline">→ Stage2 (b) → Stage3 (a, b)</code> and not <code class="codeinline">→ Stage3 (a, b) → Stage2 (b)</code>. Wouldn't that mean that the the pairs will come out in reverse order?</p><p>Nope. The third weird thing is the handling of processes that don't consume all the input with a <code class="codeinline">∀</code> loop. At the end of their execution, they're assumed to have an implicit <code class="codeinline">PassThrough</code> stage at the very end.</p><p>So if you were to call <code class="codeinline">Stage3 (9, 9)</code> on <code class="codeinline">(1, 2, 3)</code>, the output will be <code class="codeinline">(99, 1, 2, 3)</code>.</p><p>The final call to <code class="codeinline">Stage2</code> ends with a pipeline in a backwards order like <code class="codeinline">Stage3(8, 9) → Stage3(7, 8) → Stage3(6, 7) ... → Stage3(2, 3) → Stage3(1, 2)</code>. Regardless the output will be in the correct order because each <code class="codeinline">Stage3</code> inserts its own item into the first position.</p><p>Also, this means that <code class="codeinline">∀ b; → Stage3 (a, b) → Stage2 (b)</code> wouldn't even work; it would infinitely recurse since <code class="codeinline">∀ b</code> will keep taking one item off and <code class="codeinline">Stage3</code> will keep putting one back on.</p><p>That's also what's going on with the weird order of <code class="codeinline">→ JoinBeziers (...) → OffsetBezier (...)</code>.</p><p>The backwards order thing is clearly confusing, because <code class="codeinline">RoundJoin</code> has a bug:</p><pre class="codeblock"><code>RoundJoin (P:Point, u:Vector, v:Vector, o:Number) : Bezier >> Bezier
    ϵ = 0.1
    (A, C) = (P + ou, P + ov)
    w      = (A ⟂ C) ? u
    if u ∙ w ≥ 1 - ϵ
        N = P + ow
        B = N + (N - (A ~ C))
        >> (A, B, C)
    else
        → RoundJoin (P, u, w, o) → RoundJoin (P, w, v, o)
</code></pre><p>The last line should be <code class="codeinline">→ RoundJoin (P, w, v, o) → RoundJoin (P, u, w, o)</code>, not the other way around.</p><h4>Commentary</h3><p>My commentary on this is that it's all very weird. Like, what a strange syntax for what's essentially a <code class="codeinline">peek</code> operation.</p><p>I'm pretty sure I've written pipelines that work like this. But to my credit I also haven't published that code to the world saying "this is the official way to implement peek in my streaming language, and also this is the Maxwell's equations of rendering."</p><p>Maybe that was a little harsh. As far as I've seen, Dan Amelang has never said the Maxwell line.</p><p>Interestingly, there <i>was</i> a <code class="codeinline">peek</code> operator in the language, but it was removed! Here's a function from an old version of the gezira stroking system:</p><pre class="codeblock"><code>PrepareBeziersForJoin : Bezier >> (Bezier, Bezier)
    & (A, B, C)
    first = 1
    D = 0 : Point
    E = 0 : Point
    F = 0 : Point
    ∀ (D', E', F')
        if first
            first' = 0
        else
            >> ((D, E, F), (D', E', F')) >> ((F', E', D'), (F, E, D))
    if A = F ∧ first = 0
        >> ((D, E, F), (A, B, C)) >> ((C, B, A), (F, E, D))
</code></pre><p>Here the <code class="codeinline">&</code> operator is <code class="codeinline">peek</code>, binding to <code class="codeinline">(A,B,C)</code>. Presumably <code class="codeinline">&</code> was chosen because Dan didn't have time to pour over the unicode table to find something else, and so he begrungingly using a character already on his keyboard. Whincing with every keystroke. Maybe that was a little harsh too.</p><p>Personally, I don't see what's wrong with <code class="codeinline">peek</code>. It's a very normal thing to do with streams. It's the most obvious way to implement join/cap.</p><p>Another thing to note is the different kind of recursion. In the rasterization code, recursion was done with the <code class="codeinline"><<</code> operator.</p><pre class="codeblock"><code>OffsetBezier (Z:Bezier, o:Number) : Bezier >> Bezier
    ϵ = 0.1
    (A, B, C) = Z
    (u, v)    = (A ⟂ B, B ⟂ C)
    M         = (A ~ B) ~ (B ~ C)
    if u ∙ v ≥ 1 - ϵ
        w = (A ~ B) ⟂ (B ~ C)
        D = A + ou
        F = C + ov
        N = M + ow
        E = N + (N - (D ~ F))
        >> (D, E, F)
    else if A ≠ B ≠ C
        → OffsetBezier ((M, B ~ C, C), o) → OffsetBezier ((A, A ~ B, M), o)
</code></pre><p>Here, the job of <code class="codeinline">OffsetBezier</code> is to emit beziers that are offset to the left. If the bezier isn't straight enough, split and recurse.</p><p>In the rendering code, this would have been implemented with <code class="codeinline">>></code> and <code class="codeinline"><<</code>. But here it can't. Because it can't have a <code class="codeinline">∀</code> loop in its body. Because its input stream isn't being fed raw beziers, only already-offset beziers. Because the raw beziers aren't being stored in the input stream, they're being stored in the call stack. Because of this weird way of writing <code class="codeinline">peek</code>.</p><p>The <code class="codeinline">∀ x; →</code> syntax has weird semantics. You gain the ability to write cursed functions like this:</p><pre class="codeblock"><code>Cursed () : Number >> Number
  -- Discard the first number >= 10, leaves the rest.
  ∀ x
    if x < 10 = 0
      >> x
    else
      → (→)
</code></pre><p>I think the semantics of <code class="codeinline">∀</code> should be "the following block gets run for every item in the input stream". Why else name it <code class="codeinline">∀</code>?</p><p>I think the stroking system begs the question of why there are two versions of recursion. The <code class="codeinline">∀ x; → Self</code> concept can do everything the <code class="codeinline"><<</code> concept can and more. So why have both?</p><p>Surprisingly, my suggestion for all this would be to not change much.</p><p>First, the thing about the backwards function application doesn't bother me. It's the same order for the <code class="codeinline"><<</code>, so it's consistent. I just find it funny.</p><p>The stroking system is the only place in gezira that does this. So we just need to replace this pattern in the stroking system with something else.</p><p>I don't suggest trying to disallow the <code class="codeinline">∀ x; →</code> syntax or even changing how it works. I think that's a lot effort for no real gain. If the only instance is removed, I think that's fine.</p><p>Part of the reason for structuring the stroking system like this is to gain the ability to use functions in gezira like functions in other languages. Dan structured the gezira code so that miter join generation happens in <code class="codeinline">MiterJoin</code>, etc.</p><p>But if you have a syntax for calling functions, you're one step away from recursion. And now you're back to having 2 kinds of recursion in your language.</p><p>We already have something like regular functions in gezira. They're called operators. If you want to keep the code for the different caps and joins separate, I suggest turning them into operators.</p><p>It would be nice if there was a way to call gezira functions like functions in a normal language, one input. Like if <code class="codeinline">OffsetBezier</code> was a function that <code class="codeinline">OffsetAndJoin</code> could use, but also a was a standalone function that could be called in user code to offset beziers.</p><p>Note that <code class="codeinline">CapBezier</code> and friends are NOT that currently. Despite looking like a function <code class="codeinline">Bezier >> Bezier</code>, they don't operate on any items in its input stream. So turning them into operators doesn't lose you any functionality.</p><p>Finally, I think the addition of a <code class="codeinline">RotateOne</code> function would let you get rid of the <code class="codeinline">∀ x; →</code> peeking pattern. It would take the element on top of the input stream and put it on the bottom. You can implement <code class="codeinline">RotateOne</code> using the current syntax like this:</p><pre class="codeblock"><code>AppendEnd (end: Number) : Number >> Number
  ∀ x
    >> x
  >> end

RotateOne () : Number >> Number
  ∀ x
    → AppendEnd (x)
</code></pre><p>Now you could zip pairs together:</p><pre class="codeblock"><code>StrokeBezierPath_2 (width:Number, limit:Number, cap:Number) : Bezier >> Bezier
    → SanitizeBezierPath () →
      DupCat (→ (→),
              → Reverse () → ReverseBeziers ()) →
      OffsetBezier_2 (width) →
      DupZip (→ (→),
              → RotateOne ()) →
      OffsetAndJoin_2 (width, limit, cap)
</code></pre><p><code class="codeinline">OffsetBezier_2</code> is like <code class="codeinline">OffsetBezier</code>, only now it's a properly operating on its input stream. A modified <code class="codeinline">OffsetAndJoin_2</code> receives adjacent <code class="codeinline">(Bezier, Bezier)</code> pairs in its input stream, along with 2 <code class="codeinline">(start, end)</code> and <code class="codeinline">(end, start)</code> pairs in the appropriate spots in the stream.</p><p>In the original code, caps were only ever added to curve ends, and joins were always applied between adjacent no matter what. But what if the stream contains just 2 beziers that aren't connected? The join will be messed up, and there won't be enough caps.</p><p>I suggest instead making the determination just based on bezier pairs. If adjacent pairs are touching, emit a join. If they aren't touching, emit a cap.</p><pre class="codeblock"><code>OffsetAndJoin_2 (o:Number, l:Number, c:Number) : (Bezier, Bezier) >> Bezier
    ∀ ((A, B, C), (D, E, F))
        -- offset (A, B, C)
        
        if C = D
            -- endpoints are touching, this is a join
        else
            -- endpoints are not touching, this is a cap
</code></pre><p>Interestingly, gezira used to have <code class="codeinline">Mix</code> and <code class="codeinline">Interleave</code> builtin functions that solved this with a slightly different approach. But they were removed at some point, and I don't know why.</p><h3 class="section_heading">Closing</h3><p>I think I really scraped the bottom of the barrel on everything interesting to say about gezira. Here are some extra things for looking into if I ever find myself wanting more.</p><p>I didn't really look at the filtering code in gezira. I'm not too interested in it at the moment, but it's there.</p><p>There's a tons and tons of code <a href="https://tinlizzie.org/updates/">here</a>, and I have no idea what any of it does. It's almost certainly an interesting dive into the history of Squeak (of which I know little), VPRI, and Alan Kay's projects.</p><p>I want to mention <a href="https://github.com/Twinside/Rasterific">Rasterific</a>, if only because of how much work was put into it. It's a Haskell reimplementation of gezira. It emulates the gezira algorithm, but all in Haskell. It also significantly expands the set of operations. There are cubic beziers, dashed strokes, [todo: more]. It was started back in 2013.</p><p>I said at the beginning that Frank was never released. However, there is a build for iPad <a href="https://tinlizzie.org/~bert/frank4ipad/">sitting on the tinlizzie server</a>. I don't have an old 2011 jailbroken iPad sitting around, but I think it'd be super cool if someone installed it showed it off.</p><p>What was HARC? I only know keywords. How was it funded? How did it die? <a href="https://web.archive.org/web/20240314183910/https://harc.ycr.org/">Here</a> is the last archived copy of HARC's website.</p><p>[todo: more things to look into]</p><h4>People</h3><p>What are the main people up to these days?</p><p>Alan Kay is getting up there in age. He still makes public appearances, but I haven't seen any evidence of him doing any more research or development. He's 85 years old now.</p><p>That mustache he rocked for the last 50 years has now turned into a full Santa Claus beard. Why? That's probably what this post <i>should</i> have been about. No one gives a fuck about this gezira shit. What happened to the 'stache? The people need to know!</p><p>Dan Amelang: who knows? He's very much the main character of this post, but outside of this work I don't know much about him. He's still alive, but as for what he's working on? No idea.</p><p>Professor Ian Piumarta: still active, still doing much the same sort of research.</p><p>Alex Warth: still active, still doing much the same sort of research. I saw the talk he gave at at (with?) the Ink & Switch people last year.</p><p>Yoshiki Ohshima: still quite active. Tons of projects. He updates https://tinlizzie.org/ohshima/ often with his new projects and accomplishments. [todo: whois on tinlizzie]</p><h4>Further Gezira</h3><p>I definitely think there's directions to take the base gezira, if someone wanted to take up the mantle.</p><p>In my opinion, edge sharing is the single biggest problem in gezira at the moment. If two polygons share an edge, there should be no visible gap.</p><p>For example, I made a couple changes that allows me to do subpixel rendering:</p><p><table><tr style="vertical-align:top"><td width=33.333%><figure><img src="letter_g.svg" style="width:100%"><figcaption>What is a subpixel rendering demo without text? This is Liberation Serif's g. Liberation Serif is distributed as a TrueType font, which uses quadratic beziers for shape outlines.</figcaption></figure></td><td width=33.333%><figure><img src="letter_g_subpixel_2.svg" style="width:100%"><figcaption>Subpixel coverage.</figcaption></figure></td><td width=33.333%><figure><img src="letter_g_subpixel.svg" style="width:100%"><figcaption>Simulation of what this looks like rendered.</figcaption></figure></td></tr></table></p><p>Another obvious next step is analytic temporal AA, and support for animation.</p><p>I think the <code class="codeinline">Compositor</code> subsystem is too much. I think with enough work it can be made drastically simpler.</p><p>[talk about edge sharing in the coverage part]</p><p>I'm not clued in to the advances in 2D rendering over the last couple decades. Are there any appropriate order-independent transparency techniques?</p><h4>Opinions</h3><p>I aught to address my opinions on this whole thing.</p><p>[todo: my opinions on the VPRI goal as a whole]The whole conceit, the practicality and beauty and <i>rightness</i> of a computing stack redone through radical simplicity, is a siren song to me. Distressing, impossible to ignore, and dangerous.</p><p>I also think that such an endeavor is doomed to fail. I have so many thoughts on this, from so many different angles, I couldn't possibly write them all down here.</p><p>That being said I try to follow the call in my own way. I'm writing this post in a homemade text editor, building the site with a homemade static site generator, on one of those build-your-own linux systems called Guix. I have tons of homemade tools that I use every day, on my computers, my phone, my watch, my home. Every time I use a piece of software someone else wrote my first thought is "I could definitely make my own version."</p><p>If I were running Fedora, I'd alias <code class="codeinline">yum</code> to <code class="codeinline">yuck</code>.</p><p>Let's elide any discussion of what these behaviors mean about me, and if they've affected my life in a positive or negative way.</p><p>I read a lot about weird computing systems and computing models and other big theory-of-everything projects like the VPRI. Probably far more than is healthy. Ranking the VPRI among them all, I'd give them a thumbs up. Pretty cool.</p><p>The first couple years saw tons of progress. If that velocity had been maintained through the years, that would have been incredible.</p><p>I would have liked to see more detailed output. The progress reports are nice, but they aren't that detailed. The more traditional papers were nice, and I would have loved to see more of those, specifically more on things that were <i>actually in the running system!</i></p><p>The irony here is that Alan Kay has probably said more words on camera than I've said in my entire life. But I don't want to hear your Maxwell's equations metaphor! I want teardowns! Like this!</p><p>I feel I've been spoiled when it comes to this. I tune in monthly to read 100 rabbit's progress reports. The entirety of Dynamicland's archives are an incredible read. I get to live vicariously through these, and others.</p><p>They are a safe way of engaging with projects and ideas that enamor me. I don't have to deal with the messy, human part of these projects. I don't have to deal with my own emotions about messing up something others depend on/find joy in, or about publicly falling short.</p><p>Most of all I don't have to be in the thick of it, see all the gory details and compromises, and see the magic fade away.</p><p>Which brings me to my next question: did gezira accomplish its goal?</p><p>[todo: my opinion on "has gezira accomplished its goal? alan kay's goal?"]</p><p>Did gezira accomplish the goal of being Frank's rendering system with a small LOC footprint? It's undeniably very small for its capabilities, and it successfully powered Frank. So yes.</p><p>Does it succeed at being the Maxwell's Equations of Rendering? Or does it succeed at being "runnable math" (another of Alan Kay's favorite phrases)?</p><p>[todo: I don't like this bit. Too low-hanging. Remove.]</p><p>For context, here are Maxwell's equations in a vacuum:</p><p>$$\begin{aligned}\nabla \cdot E & = 0 \\\nabla \times E & = - \frac{\partial B}{\partial t} \\\nabla \cdot B & = 0 \\\nabla \times B &  = \mu_0 \epsilon_0 \frac{\partial E}{\partial t}\end{aligned}$$</p><p>Here's a pretty simple application of them: showing that all electromagnetic fields in a vacuum obey the wave equation $\nabla^2 V = c^2 \frac{\partial^2 V}{\partial t^2}$, and all such waves have the same velocity.</p><p>$$\begin{aligned}\nabla \times E & = - \frac{\partial B}{\partial t} \\\nabla \times (\nabla \times E) & = - \nabla \times \frac{\partial B}{\partial t} \\\nabla (\nabla \cdot E) - \nabla^2 E & = - \frac{\partial}{\partial t} (\nabla \times B) \\\nabla^2 E & = - \frac{\partial}{\partial t} (\mu_0 \epsilon_0 \frac{\partial E}{\partial t}) = - \mu_0 \epsilon_0 \frac{\partial^2 E}{\partial t^2} \\\end{aligned}$$</p><p>You can't do anything like this with Nile or Gezira. The standard I'm using here for true "runnable math" would be the <a href="https://mitp-content-server.mit.edu/books/content/sectbyfn/books_pres_0/9580/9580.pdf">work of Gerald Sussman</a>.</p><p>[todo: my opinions on gezira as a whole]</p></div><div style="background-color: #222; padding: 1em; color: #fafafa">Written by Daniel Taylor.<br>Email: contact@djtaylor.me<br><br><span style="color: #aaa">© 2024 by Daniel Taylor</span></div><script id="MathJax-script" async src="/3rd-party/mathjax/tex-mml-chtml.js"></script><script>window.MathJax = { tex: { inlineMath: [['$', '$']] } };</script></body></html>