<html>
	<head>
		<meta charset="UTF-8">
		
		<style>
			body {
				-webkit-text-size-adjust: none;
				-moz-text-size-adjust: none;
				-ms-text-size-adjust: none;

				word-wrap: break-word;
				font-family: sans-serif;
				line-height: 1.2rem;
			}

			.nav {
				display: inline-block;
			}

			.navitem {
				display: inline-block;

				padding: 10px;
				min-width: 100px;
				text-align: center;

				color: #fff;
				text-decoration: none;

				transition: background 0.25s ease;
			}

			.navitem:hover {
				background: #b50;
				/*color: #fa0;*/
				transition: background 0.125s ease;
				color: #fff;
			}

			/* 4*(navitem-width + 2*navitem-padding) + 2*body-padding = 4*(100px + 10px) + 2*(10px) = 500px */
			@media (max-width: 500px) { 
				.navitem {
					width: calc(50% - 20px);
				}
			}

			.codeblock {
				border: 1px solid;
				padding: 1em;
				overflow: auto;
			}

			.codeinline {
				border: 1px solid #aaa;
				border-radius: 3px;
				background-color: #e6e6e6;

				/* Not very good. Will probably depend on the metrics of the font used. Oh well. */
				padding-left: 0.1em;
				padding-right: 0.1em;
			}

			.primary_link {
				color: #000;
				text-decoration: none;
			}
			.primary_link:hover {
				color: #b50;
				text-decoration: none;
			}

			/* For dealing with img()[] elements */
			figure {
				border: 1px solid #888;
				background-color: #e6e6e6;

				margin: 0;
				padding: 1ch;

				display: inline-flex;
				flex-flow: column;
			}
			figcaption {
				margin-top: 0.5rem;
				align-self: center;
			}
			img {
				align-self: center;
				max-width:100%%
			}

			blockquote {
				margin: 0;
				padding-left: 2ch;
				padding-top: 1em;
				padding-bottom: 1em;
				padding-right: 2ch;
				border: 1px solid #888;
				background-color: #e6e6e6;
				border-radius: 3px;

				font-style: italic;
			}

			h2 {
				font-size: 1.25rem;
			}

			.section_heading {
				border-top: 1px dotted;
				padding-top: 1rem;
			}

		</style>

		<meta name="viewport" content="width=device-width, initial-scale=1">
	</head>
	<body style="max-width:980px; padding: 10px; margin:auto; background: #e6e6e6">
		<div style="background: #fafafa; padding: 20px">
			<div><h1 style="margin-top: 0.5em; margin-bottom: 0.3em">djtaylor.me</h1></div>
			<div><i>Insert tagline here</i></div>
		</div>
		<div style="background: #222; color: #fafafa">
			<a href="/" class="navitem">Blog</a><a href="/thought/" class="navitem">Thoughts</a><a href="/portfolio/" class="navitem">Projects</a><a href="/resume/" class="navitem">Resume</a><a href="/physics/" class="navitem">Physics</a>
		</div>

		<div style="background: #fafafa; padding: 20px"><h2 style="margin-bottom:0.5rem">Gezira</h2><i>Pub. 2025 Sep 30</i><p>[todo: mention- https://news.ycombinator.com/item?id=19844088]</p><h3 class="section_heading">VPRI</h3><p>In 2001 Alan Kay co-founded the Viewpoints Research Institute, or VPRI. It started as an outreach organization for Squeak, but around 2006 it shifted focus to research.</p><p>It was a typical Alan Kay endeavor: reinvent computing in the image of whatever has been on his mind recently. This time it's source code size. In my own words, I'd say the problem statement is "can we make a computing system that has 95% of the functionality, 95% of the ease of use, but 1/10000th of the lines of code of systems today?", where "today" meant 2005. He often mentioned a target of 20kLOC for the whole computing stack.</p><p>Their primary output were research papers and NSF progress reports. These are listed <a href="https://tinlizzie.org/IA/index.php/Papers_from_Viewpoints_Research_Institute">here</a>.</p><p>The main vehicle by which they worked towards their goal is a program they created called Frank. Frank is one of those document-centric computing models. Documents could embed text, images, programs, etc. I don't think the source code to Frank was ever released. I've seen multiple people online talk about running Frank, but I don't know where they found the source.</p><p>The VPRI's <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=0639876">5-year NSF grant</a> concluded in 2012. After that the VPRI slowed down significantly. Their website lists 2018 as the official end of the institute, but Alan Kay is listed as an author to only 2 papers after 2013, down from multiple papers a year. In 2016 the VPRI joined Y-Combinator's HARC, during which not much is known publicly. [todo: more?]</p><h3 class="section_heading">Gezira</h3><p>In all the annual NSF progress reports, a big deal is made about the rendering system. That's what I want to talk about.</p><p>The goal was to come up with a way to do all of the 2D graphics necessary to power Frank. It would need to render text and shapes and such in as few lines of code as possible. They would do this by creating language that could efficiently describe how to render, and compilers that could translate this description into a runnable artifact.</p><p>This was spearheaded by a man named Daniel Amelang. He was a contributor to the Cairo graphics library in 2006 and 2007. He joined the VPRI to work on the graphics problem. The goal was to create a graphics system that would support all of the major features of Cairo, but in much less code.</p><p>The end result was Gezira, a renderer written in just a couple hundred lines. It supports beziers, fills, strokes, antialiasing, some limited texture filtering, many compositors, different caps and joins. It was written in a custom DSL made for the task. It was run in Nile, a custom stream processor also made for the task. There were other things in the mix, like a grammar parser called OMeta, and scheme variant called Maru. But in practice, Gezira was written and ported several times to multiple different languages. The Gezira algorithms and the stream processor were the important things.</p><p>Gezira would take in a stream of shapes, a pipeline description, and output a stream of pixel colors.</p><p>People like Alan Kay like to promote the idea that we should be chasing "the Maxwell's equations of ___." The Maxwell's equations of rendering would be a short formula, only a couple lines long, which would encompass all of 2D rendering, all edge cases included.</p><p>And so that's what they did.</p><p>Here is their "rendering formula". For a pixel with opposite corners (x, y) and (x+1, y+1), the "coverage" of a single line segment AB is:</p><p>$$\begin{aligned}s(P,Q) & = (Q_y - P_y)(x + 1 - \frac{Q_x + P_x}{2}) \\g(P) & = \min(x+1, \max(x, P_x)), \min(y+1, \max(y, P_y)) \\o(P) & = \frac{1}{m} (g(P)_y - P_y) + P_x, m (g(P)_x - P_x) + P_y \\\text{coverage}(AB) & = s(g(A), g(o(A))) + s(g(o(A)), g(o(B))) + s(g(o(B)), g(B))\end{aligned}$$</p><p>To compute the combined coverage of multiple line segments for a given pixel, you sum them:</p><p>$$\min( | \sum{coverage(AB_i)} | , 1)$$</p><p>This is how it is written on all of Gezira's materials. As far as I can tell, the formula is always presented as-is, and is rarely explained.</p><p>Personally, I think this form is unnecessarily opaque. Here's my version:</p><p>For a line $AB$ and a a pixel with opposite corners (x, y) and (x+1, y+1), the coverage of that line for that pixel is</p><p>$$\begin{aligned}m = & \frac{B_y - A_y}{B_x - A_x} \\\text{trapezoid}(P,Q) = & (Q_y - P_y) \left( x + 1 - \frac{Q_x + P_x}{2} \right) \\\text{snap}(P) = & \min(x+1, \max(x, P_x)), \min(y+1, \max(y, P_y)) \\\text{clip}(P) = & \text{snap} \left( \frac{1}{m} (\text{snap}(P)_y - P_y) + P_x, m (\text{snap}(P)_x - P_x) + P_y \right) \\\text{coverage} = & \text{trapezoid}(\text{snap}(A), \text{clip}(A)) + \\& \text{trapezoid}(\text{clip}(A), \text{clip}(B)) + \\& \text{trapezoid}(\text{clip}(B), \text{snap}(B))\end{aligned}$$</p><p><table><tr style="vertical-align:top"><td width=50%><figure><img src="rendering_formula_simple.svg" style="width:100%"><figcaption>The "coverage" of a line segment for a pixel is the intersection of the area sweeped to the right, and the area of the pixel.</figcaption></figure></td><td><figure><img src="rendering_formula.svg" width="100%"><figcaption>If parts of the line segment lie outside the pixel, the coverage is broken up into pieces and summed together.</figcaption></figure></td></tr></table></p><p><code class="codeinline">trapezoid(P,Q)</code> computes the area of a trapezoid formed by P, Q, and the projections of P and Q on the <i>right edge</i> of the pixel. <code class="codeinline">snap(P)</code> and <code class="codeinline">clip(P)</code> are used to compute which portion of the line is inside the pixel, if any. These are then put together to compute the area of the intersection of the pixel square and the line, if the line were <i>swept right</i>.</p><p>The area is signed as well, thanks to the $(Q_y - P_y)$ term in <code class="codeinline">trapezoid</code>. So if we were computing the total coverage of a closed polygon, any extra coverage for a line segment will get undone by a later line segment that closes the loop.</p><p>The total coverage has that extra $\min( | ... | , 1)$ term to not enforce a particular winding direction, and to handle multiple overlapping shapes.</p><p>This should remind you of other polygon area and winding rule algorithms. Pretty standard technique. It naturally supports the CW/CCW winding rule.</p><p>It does NOT support additional filtering, though since traditional filters are also linear it's not out of the question. It also ONLY supports closed polygons, though it does allow holes by winding them in the opposite direction.</p><p><figure><img src="shutter.svg" style="align-self: center; max-width:100%"><figcaption>A square wave pattern realized with rectangles. It has a frequency of 7/8 = 0.875</figcaption></figure></p><p><figure><img src="alias.svg" style="align-self: center; max-width:100%"><figcaption>Pixel coverage of this pattern as reported by gezira. Note that the 7/8 frequency has aliased to a frequency of 8, and attenuated down to a peak-to-peak amplitude of $145 - 109 = 36 \approx 255 \, \text{sinc}(7/8)$</figcaption></figure></p><p>Why does <code class="codeinline">trapezoid(P,Q)</code> sweep the area out to the right instead of left? I won't get into it now, but it's because Gezira renders scanlines from left to right. If you sort the line segments you can render an entire scanline by updating an accumulator.</p><p>It's important to note that the gezira source code does NOT use the formula as described. For reasons we'll get into later, gezira actually pre-clips line segments. The line segments passed into the coverage computation code are already entirely contained in their given pixel. So there's no need for <code class="codeinline">clip()</code> and <code class="codeinline">snap()</code>.</p><p>The rendering formula that's actually being used looks like:</p><p>$$\text{coverage}(AB) = (B_y - A_y) \left( x + 1 - \frac{Bx + Ax}{2} \right)$$</p><p>So if this rendering formula is supposed to be the basis of all rendering that powers this computing system, how does that work? There's more you might want to render than filled polygons. How does stroking work? Or texturing?</p><p>Stroking works by offsetting the curve in both directions and rendering as a closed shape. More on this later.</p><p>Texturing works by taking a point sample of the texture at the center of a pixel and weighting it by the coverage to blend. More on this later as well.</p><h3 class="section_heading">The demo site</h3><p>The Nile and Gezira source are published <a href="https://github.com/damelang/nile">here</a> and <a href="https://github.com/damelang/gezira">here</a> respectively. From what Dan Amelang has said, it isn't in build-able condition. Significant work will have to be done to get it working <a href="https://github.com/damelang/nile/issues/3#issuecomment-517508949">apparently</a>.</p><p>Luckily, the output from some of the build stages are checked in to the repo, so we can still observe a lot. For example, you can see the gezira's .c files.</p><p>Despite the fact that there's an "official" repo, there seem to be lots of versions of the source out there. It's like every time I see some source listing from this project there's some variation in syntax or data type name or something.</p><ul><li>There's what I'm calling the "official" Gezira source, located in <a href="https://github.com/damelang/gezira/tree/master/nl">this folder</a> in Gezira github repo.</li><li>There's the version written in the comments of the <a href="https://github.com/damelang/gezira/blob/master/hs/gezira.hs">Haskell implementation</a>.</li><li>There's the version in Nile repo, listed <a href="https://github.com/damelang/nile/blob/master/compilers/js/nile-compiler.html">as part of a compiler demo</a>.</li><li>We're going to be looking at a particular demo site that was made for Gezira. That site has yet another version of the source, albiet very similar to the Nile repo version.</li><li>todo: I know there's more]</li></ul><p>There are also several full reimplementations in other languages.</p><p>We're going to be looking at the Gezira source shortly, but I'm torn between which version to show. The "official" source is the most obvious one. When someone wants to see the source code to Gezira they'd go to the gezira repo and look under <code class="codeinline">nl/</code>. </p><p>However, I like the js demo code the most for its stylistic choices. From the file modified dates it also seems like the latest edition. And most importantly, of all of the Gezira versions, this is the only one that <i>actually runs!</i></p><p>Unfortunately, it's not perfect. There are some stylistic changes that were made to get the js demo working. For example, in the "official", source operators get applied elementwise over vectors implicitly, which is nice. I guess they never implemented that in the js demo.</p><p>Whatever. We're going to be looking at the js demo source code. From now on I'm calling this the "latest" source.</p><p>What I'm trying to get at is that this project, though dead and abandonded, is <i>very much</i> a work-in-progress.</p><p>If we're not building it, then what are we doing? Well, the main way I think anyone understands Nile and Gezira these days is from <a href="https://tinlizzie.org/dbjr/high_contrast.html">Bret Victor's demo site</a>.</p><p>Yup! The famous Bret Victor made a little demo site for Gezira in 2012, explorable-explanations style. You can mouse over pixels, beziers, samples, and see how the data flows through the pipeline. You can click the stages to expand and see the sub-stages! Next to each stage is that stage's source code, and as you hover over the elements you see the branches that element took in the source. Very cool!</p><p><figure><img src="bret.png" style="align-self: center; max-width:100%"></figure></p><p>And there's actually more to the site than you see. If you open up the console and paste <code class="codeinline">document.getElementById("mySidebar").style.display="block"; document.getElementById("mySidebar").style.position="relative";</code> you get a menu where you can pick different prepared scenerios.</p><p>This site is a huge help in understanding Gezira.</p><p>The site does have two small, pretty inconsequential bugs: <code class="codeinline">PadGradient</code> should be <code class="codeinline">Real >> Real</code> and not <code class="codeinline">Point >> Point</code>, and <code class="codeinline">Texture</code> should take in <code class="codeinline">SpanCoverage</code> not <code class="codeinline">EdgeSpan</code>.</p><p>It's important to mention that the demo site is NOT interpretting Gezira code. The source listings on the side <i>are</i> Gezira source code, but the interactive stuff is rewritten by hand in javascript. So syntax errors like these don't affect the demo.</p><p>Also, the way that highlighting works on the site can be confusing. The way that <code class="codeinline">CombineEdgeSamples</code> works makes it seem like there's an off-by-one error, even though there isn't. [todo: expand or remove]</p><p>The rest of this post is going to be a breakdown of the Gezira source, specifically the part shown on the demo site. I'll be going through each stage, explaining the code, and giving my thoughts and opinions.</p><h3 class="section_heading">Rasterize</h3><p>Earlier you may have been saying "the rendering formulas are nice, but they're only for line segments? What about curves? They're pretty important for 2D rendering." And you'd be right.</p><p>Gezira actually operates exclusively on beziers, which it then deconstructs into line segments at the last moment. Surprisingly, it uses <i>quadratic</i> beziers instead of cubic. This is presumably because due to the focus on text, and because TrueType only supports quadratic beziers?</p><p>(Interestingly, in <a href="https://www.youtube.com/watch?v=HAT4iewOHDs&t=1025s">this talk</a> given by Dan Amelang, he explicitly says that the beziers are cubic. However <i>none</i> of the versions of the gezira source I've seen support cubic beziers.)</p><p>The first major stage of rasterization takes in a stream of quadratic beziers and output <code class="codeinline">CoverageSpan</code>s.</p><pre class="codeblock"><code>Rasterize () : Bezier >> SpanCoverage
    → DecomposeBeziers () → SortBy (1) → SortBy (2) → CombineEdgeSamples ()
</code></pre><p>The pipeline here is self-explanatory.</p><p>There's actually a difference here between the "latest" source and the "official" source. The "official" source lists this:</p><pre class="codeblock"><code>Rasterize : Bezier >> CoverageSpan
    ⇒ DecomposeBeziers → SortBy (@x) → SortBy (@y) → CombineEdgeSamples
</code></pre><p>The eagle-eyed might notice two different operators here: <code class="codeinline">⇒</code> and <code class="codeinline">→</code>. In my editor they look <i>very</i> similar. The <code class="codeinline">⇒</code> operator seemed to be used when beginning a new pipeline, and <code class="codeinline">→</code> continued it. I'm glad this was changed.</p><p>The other differences aren't important. In the "official" source <code class="codeinline">DecomposeBeziers</code> and <code class="codeinline">CombineEdgeSamples</code> don't have parameter lists, but that's just a syntax change.</p><p>Like I've mentioned already, the source listed on the demo site actually comes from Nile js compiler demo. So the source listed here is mostly the same, but sometimes won't match up exactly with the demo site.</p><h4>DecomposeBeziers</h3><p>Anyways, here's the first stage:</p><pre class="codeblock"><code>DecomposeBeziers () : Bezier >> EdgeSample
    ϵ = 0.1
    ∀ (A, B, C)
        P = ⌊A⌋ ◁ ⌊C⌋
        if ∧(P ≤ A ≤ P + 1 ∧ P ≤ C ≤ P + 1)
            (x, y) = P
            (w, _) = P + 1 - (A ~ C)
            (_, h) = C - A
            >> (x + 0.5, y + 0.5, wh, h)
        else
            M            = (A ~ B) ~ (B ~ C)
            ( min,  max) = (⌊M⌋, ⌈M⌉)
            (Δmin, Δmax) = (M - min, M - max)
            N = { min, if |Δmin| < ϵ
                  max, if |Δmax| < ϵ
                    M,     otherwise }
            << (N, B ~ C, C) << (A, A ~ B, N) 
</code></pre><p>This step does a lot of work. It takes each bezier, recursively breaks it apart into smaller beziers until it's "small enough" and fits inside a single pixel square, then applies the simplified rendering formula from above, to finally output the contribution of THAT bezier piece in THAT pixel.</p><p>Let's take it a bit at a time.</p><p>It first tests whether the bezier is fully contained in a single pixel by checking its two endpoints. There's an obvious problem with this, but I'll get to that later.</p><p>The formula it uses for this is:</p><pre class="codeblock"><code>P = ⌊A⌋ ◁ ⌊C⌋
if ∧(P ≤ A ≤ P + 1 ∧ P ≤ C ≤ P + 1)
  ...
</code></pre><p>Being a streaming language, gezira takes after APL. So we're going to be seeing lots of funny symbols everywhere. Maxwell's equations and all that. [todo: I keep using the word streaming, but do i mean arrays? I'm sure some plt gigadorks differentiate the two words.]</p><p><code class="codeinline">floor</code> and <code class="codeinline">ceil</code> are very common and useful in graphics, so they're given their own operators. In nile, these operators are applied elementwise.</p><p>We also see the <code class="codeinline">and</code> operator, <code class="codeinline">∧</code>, being applied once elementwise <code class="codeinline">(Bool², Bool²) >> Bool²</code>, and then again across elements <code class="codeinline">Bool² >> Bool</code>.</p><p>The <code class="codeinline">◁</code> operator computes the min of two numbers. It was chosen because it kinda looks like a <code class="codeinline"><</code> sign. Similarly the <code class="codeinline">▷</code> operator computes max. Because min is commutative, it's envisioned here as an infix operator. So you can chain them together like <code class="codeinline">A ◁ B ◁ C</code>! Same with max.</p><p>And actually, min and max associate (but don't commute) with each other. So statements like <code class="codeinline">min ▷ A ◁ max</code> make sense. This is used to clamp numbers in a couple places in gezira. Very cool! This is a nice demonstration of the STEPS conceit. [todo: have i mentioned STEPS yet?]</p><p>This is slightly different from the source on the demo site:</p><pre class="codeblock"><code>inside = (⌊ A ⌋ = ⌊ C ⌋ ∨ ⌈ A ⌉ = ⌈ C ⌉)
if inside.x ∧ inside.y
</code></pre><p>This isn't used in the "latest" source because it has a small bug:</p><p><figure><img src="pixel_inclusion.svg" style="align-self: center; max-width:100%"></figure></p><p>In the image above, example line segments 1, 5, 6, and 7 are entirely contained in a pixel boundary. Number 6 looks wrong because, while it's not contained in the blue pixel square, it is entirely contained in the <i>next pixel to the right</i>. Remember, in this stage pixels aren't asking which beziers they contain. The beziers themselves are asking if they are contained inside of a pixel.</p><p>It's an elegant formulation, and handles the case where one of the endpoints lie on a pixel boundary. If they do that, they'll have integer coordinates, and so <code class="codeinline">⌊A⌋ = ⌈A⌉</code>. See image above.</p><p>This works nicely in all cases but one: the case where the endpoints lie on opposite edges of a pixel square. This is the example number 7 above.</p><p>This is actually <a href="https://github.com/damelang/gezira/blob/9f3e6846f4a1732c344a3b99e5d670deac618b17/TODO#L37">mentioned in one of the TODO files</a> in the gezira git repo.</p><pre class="codeblock"><code>    - optimization: how often do we get tiny beziers with
      endpoints on opposite sides of the pixel square? We currently split
      these, but could try not doing it (with effects on visual quality)
</code></pre><p>The "latest" source fixes this by </p><p>The "latest" source version is better, but I can make it a bit simpler:</p><pre class="codeblock"><code>if ∧(⌈A⌉ - 1 <= B <= ⌊A⌋ + 1)
  ...
</code></pre><p><figure><img src="pixel_inclusion_corrected.svg" style="align-self: center; max-width:100%"></figure></p><p>Let's tackle the else branch next.</p><pre class="codeblock"><code>M            = (A ~ B) ~ (B ~ C)
</code></pre><p>Again, cool use of a DSL. The <code class="codeinline">~</code> operator calculates <code class="codeinline">(A + B)/2</code>. This one is used all the time. The idea here is to always split the beziers at the t=0.5 point.</p><p>[todo: image of A~B, B~C, and (A~B)~(B~C)]</p><pre class="codeblock"><code>( min,  max) = (⌊M⌋, ⌈M⌉)
(Δmin, Δmax) = (M - min, M - max)
N = { min, if |Δmin| < ϵ
      max, if |Δmax| < ϵ
        M,     otherwise }
</code></pre><p>This is a little messy. See, if you always split beziers at the midpoint, there are too many situations where this will recurse forever, generating smaller and smaller beziers that cross pixel boundaries. So you need to clamp the endpoints when they get "close enough."</p><p>Note that even the if is being computed element-wise! | ABBC - min | and | ABBC - max | are both computing absolute values elementwise. To compute a vector norm, you'd have to do ‖ A ‖, with the double bars. I suppose not even Nile and Gezira can get away from these sorts of problems. [todo: revisit this]</p><p>There's actually another function in the Gezira source which seems to do something very similar, <code class="codeinline">ClipBeziers</code>, which is never used.</p><pre class="codeblock"><code><< (N, B ~ C, C) << (A, A ~ B, N) 
</code></pre><p>This then recurses twice, once for each bezier half. [todo: discuss the input stream mechanics]</p><p>Now the <code class="codeinline">if</code> branch.</p><pre class="codeblock"><code>(x, y) = P
(w, _) = P + 1 - (A ~ C)
(_, h) = C - A
>> (x + 0.5, y + 0.5, wh, h)
</code></pre><p>This is just the simplified rendering equation from above. The beziers, now hopefully small, are treated as if they're line segments for the purposes of rendering.</p><p>We see that the pixel coordinates are chosen here to be 0.5 offset.</p><p>Multiplication happens by just concatenating variables. I don't know how I feel about that.</p><p>In the "official" source, the <code class="codeinline">×</code> operator for multiplication. Definitely not a fan of that. I admire his commitment to the bit, though!</p><p>So. General thoughts.</p><p>The <code class="codeinline">∧(P ≤ A ≤ P + 1 ∧ P ≤ C ≤ P + 1)</code> test is not great. Unlike the other approximation, this one can be arbitratily wrong.</p><p><figure><img src="bezier_problem.svg" style="align-self: center; max-width:100%"></figure></p><p>In this picture we have a bezier whose two endpoints are inside a single pixel, but whose peak extends outside. Because the endpoints are horizontal, the algorithm as described will compute a coverage of 0 for this bezier. In actuality it should be close to 1, and furthermore the pixel above should be seeing some additional coverage as well.</p><p>We're trying to measure the area of a bezier, but we only have the formula for the area of a line segment. So we're trying to find a good time to stop subdividing, which happens when the area of the bezier is approximately equal to the area of the line segment.</p><p>The fundamental problem is that this method tries to determine when the <i>areas</i> are close enough by measuring <i>length</i>. We need to measure area instead.</p><p>I propose instead measuring the area of the triangle <code class="codeinline">ABC</code>, formed by the two endpoints and the handle. Stop subdividing when the area goes under <code class="codeinline">ϵ</code>.</p><p>This metric is good for two reasons:</p><p>First is that this metric makes constant geometric forward progress. If the triangle represented by the bezier ABC gets subdivided, both triangles of the sub-beziers <code class="codeinline">A(A~B)M</code> and <code class="codeinline">M(B~C)C</code> will measure exactly 1/8th the area of the original triangle <code class="codeinline">ABC</code>.</p><p>Second, it directly measures what you're looking for. The smaller the are of the triangle <code class="codeinline">ABC</code>, the more colinear the points are, and the straighter the bezier. Also, the area of a bezier <code class="codeinline">ABC</code> is directly proportional to the area of the triangle <code class="codeinline">ABC</code>, with a ratio of 2/3. So this metric is directly measuring the coverage error per bezier.</p><p>Unfortunately there is no cross product or wedge products or determinants already implemented in the gezira source, so this looks a little messy. This might look something like this:</p><pre class="codeblock"><code>DecomposeBeziers () : Bezier >> EdgeSample
  ϵ2 = 0.5
  ∀ (A, B, C)
    (a, b) = B - A
    (c, d) = C - A
    if ∧(⌈A⌉ - 1 <= B <= ⌊A⌋ + 1) ∧ (|ad - bc| < ϵ2)
      ...
</code></pre><p>And actually, I think the endpoint clamping can be made better too.</p><p>Since I'm already talking about approximating beziers with lines, how about cementing this idea? Turn <code class="codeinline">DecomposeBeziers</code> into a function <code class="codeinline">Bezier >> Line</code>, and then have another function that goes <code class="codeinline">Line >> EdgeSample</code>.</p><p>Maybe something like this:</p><pre class="codeblock"><code>type Line = (A:Point, B:Point)

DecomposeBeziers () : Bezier >> Line
  ϵ = 0.5
  ∀ (A, B, C)
    (a, b) = B - A
    (c, d) = C - A
    if |(ad - bc)| < ϵ
      >> (A, C)
    else
      M = (A ~ B) ~ (B ~ C)
      << (M, B ~ C, C) << (A, A ~ B, M)

GenerateEdgeSamples () : Line >> EdgeSample
  ∀ (A, B)
    (w, h) = B - A
    (insidex, insidey) = (⌈A⌉ - 1 ≤ B ≤ ⌊A⌋ + 1)
    if insidex ∧ insidey
      P = ⌊A⌋ ◁ ⌊B⌋
      (x, y) = P
      (g, _) = P + 1 - (A ~ B)
      >> (x + 0.5, y + 0.5, gh, h)
    else
      (Ax, Ay) = A
      (midx, midy) = ⌊((A ~ B) + 0.5)⌋
      M = { (midx, (midx - Ax) h / w + Ay), if insidey
            ((midy - Ay) w / h + Ax, midy), otherwise }
      << (A, M) << (M, B)
</code></pre><p>That's 9 additional lines in exchange for some more subjective consistency. The rendering formula that is supposedly the basis for this software is expressed in terms of lines, so here's a function that computes the coverage of lines.</p><p>There's also the problem of introducing a new concept, Line. But you could fix that by removing the pointless distinction between <code class="codeinline">Point</code> and <code class="codeinline">Vector</code>.</p><p>The other idea that keeps with the <i>spirit</i> of the original source is to subdivide each bezier by the pixel boundaries, instead of at t=0.5. This still caps the maximum coverage error per initial bezier at 0.666 per pixel intersected. It's pretty easy too, since quadratic beziers are just parabolas. It does take more code, though. Enough that you'd probably want to add a new quadratic equation operator.</p><h4>Sort</h3><p>We want to compute pixel coverages for all pixels in a scanline, but we only have coverage information about the edges. So some kind of prefix sum or integral or whatever is unavoidable. If we want to do this prefix sum without touching pixels multiple times, the data has to be sorted.</p><p>So this step sorts the <code class="codeinline">EdgeSample</code>s into scanline order. There will often be multiple <code class="codeinline">EdgeSample</code>s per pixel, but also large gaps between pixels with no <code class="codeinline">EdgeSample</code>s.</p><p>I'll save my commentary about this for the next section.</p><h4>CombineEdgeSamples</h3><pre class="codeblock"><code>CombineEdgeSamples () : EdgeSample >> SpanCoverage
    (x, y, A, H) = (0, 0, 0, 0)
    ∀ (x', y', a, h)
        if y' = y
            if x' = x
                (A', H') = (A + a, H + h)
            else
                (A', H') = (H + a, H + h)
                >> (x,     y, |A| ◁ 1,          1)
                >> (x + 1, y, |H| ◁ 1, x' - x - 1)
        else
            (A', H') = (a, h)
            >> (x, y, |A| ◁ 1, 1)
    >> (x, y, |A| ◁ 1, 1)
</code></pre><p>This one will merge <code class="codeinline">EdgeSample</code>s that lie in the same pixel, and will also group together "spans" of empty interior pixels. These "spans" will have coverage 0.0 or 1.0, unless I guess your shape isn't closed? But then again, this whole algorithm won't work if the shape isn't closed.</p><pre class="codeblock"><code>(x, y, A, H) = (0, 0, 0, 0)
</code></pre><p>Usually you'd start these sorts of loops with a <code class="codeinline">x = min(edge sample xs)</code> or something. But since all <code class="codeinline">x</code>s and <code class="codeinline">y</code>s are at 0.5 offsets, setting <code class="codeinline">x = 0</code> works.</p><pre class="codeblock"><code>∀ (x', y', a, h)
  ...
>> (x, y, |A| ◁ 1, 1)
</code></pre><p>You can see here that <code class="codeinline">∀</code> is a general looping keyword. In the previous examples, <code class="codeinline">∀</code> could have maybe meant <code class="codeinline">map</code> or <code class="codeinline">map | flatten</code> or something. But here it pretty explicitly means <code class="codeinline">for</code>. There's a prologue and epilogue to the loop, and the loop is meant to run sequentially.</p><pre class="codeblock"><code>if y' = y
    if x' = x
        (A', H') = (A + a, H + h)
    else
        (A', H') = (H + a, H + h)
        >> (x,     y, |A| ◁ 1,          1)
        >> (x + 1, y, |H| ◁ 1, x' - x - 1)
else
    (A', H') = (a, h)
    >> (x, y, |A| ◁ 1, 1)
</code></pre><p>Same <code class="codeinline">x</code> coordinates accumulate coverage. New <code class="codeinline">x</code> coordinates output twice, once for the old accumulator and once for the span between the old <code class="codeinline">x</code> and new <code class="codeinline">x</code> (which can have 0 length). New <code class="codeinline">y</code> coordinates mark the end of a scanline, so output and reset state.</p><p>So, I think this is the weakest part of the algorithm.</p><p>This is the only instance of <code class="codeinline">SortBy</code> in the gezira source. This isn't necessarily a bad thing, it just gives me pause. All other parts of the rendering algorithm are pretty trivially parallelizable.</p><p>I like to think about parallelizability on a spectrum. On one end of the spectrum there's <code class="codeinline">map</code>: one in, one out, each item completely independent, no need for synchronization or communication. On the other end there's <code class="codeinline">forth</code>: a language where every single operation modifies a global variable.</p><p>Other algorithms fall along the spectrum. Pretty close to <code class="codeinline">map</code> is <code class="codeinline">reduce</code> and <code class="codeinline">search unordered list</code>. Further out would be <code class="codeinline">prefix sum</code>. Close by to <code class="codeinline">forth</code> might be <code class="codeinline">newtonian simulation</code>. In my mind <code class="codeinline">sort</code> is right in the middle of the spectrum, along with <code class="codeinline">matrix multiplication</code>.</p><p>I just think that an algorithm that requires less sorting would be good.</p><p>This is actually mentioned by Dan Amelang in <a href="https://fonc.vpri.narkive.com/rtIMYQdk/nile-gezira-was-re-1-ftw">this email</a> in the VPRI mailing list:</p><p>There's <a href="https://hhoppe.com/ravg.pdf">this 2008 paper</a> that that details a <i>very similar</i> algorithm. In this paper, they only need to sort specific edges that intersect the lower edge of pixels. It helps.</p><p>Also, I think that triangles would make things easier. Triangles are a more direct measure of coverage than curves. With triangles there's no need to do an integral across scanlines. Each one contains its own boundary information.</p><p>I can understand why the decision was made to go with curves, but it's probably not the one I would have gone with. I think triangles are more in line with the mission. For me, a big part of low-LOC and "reinventing computing" for "simplicity" is choosing representations whose essence answers the question being asked. You're trying to measure area. The most fundamental structure that embodies area is the rectangle. Rectangles have some issues when they're not axis-aligned, so the next best is the triangle.</p><p>This curve vs triangle critique isn't that big of a deal. I just think that triangle binning is better than sorting and integrating.</p><p>Part of the conceit of DSLs, from a low-LOC point of view, is similar to that of optimizing compilers. You can match patterns in the source code and replace them with larger optimized versions. In terms of LOC, it converts a <code class="codeinline">A*B</code> problem into <code class="codeinline">A+B</code>.</p><p>I bring this up because the <code class="codeinline">sum = 0; ∀ x; sum += x</code> pattern is only used three times in gezira. Once in <code class="codeinline">CalculateBounds</code>, which just does a running min/max. Once in <code class="codeinline">SumWeightedColors</code> to downsample and filter. And once in <code class="codeinline">CombineEdgeSamples</code>, summing coverage in scanlines.</p><p>(Unrelated, but <code class="codeinline">CalculateBounds</code> is weird. I have no idea why it's implemented like that.)</p><p>Nile currently doesn't attempt to do any sort of optimization for this. Multithreading and OpenCL ports were both planned but never implemented [todo: double check this]. Gezira's full generated c code is all single threaded. [todo: double check this. I know nthreads appears in one of the c demos]</p><p>Simple pattern matchers live and die on the richness of the source. If the source code can express more intent, the compiler can be much simpler. Nile currently detects this by looking for ' symbols on variables (TODO: check this, and expand).</p><p>[todo: talk about concurrency between items in the pipeline vs concurrent pipeline]</p><p>I suggest ditching the <code class="codeinline">∀</code> keyword on these 3 functions and replacing them with another primitive, one that means "prefix sum".</p><pre class="codeblock"><code>CalculateMinBounds : Bezier >> Point
  min =  999999 : Point
  ∀ (A, B, C)
    if ¬(A.y = B.y ∧ B.y = C.y)
      min' = min ◁ A ◁ B ◁ C
  >> (min, max)
CalculateMinBounds : Bezier >> Point
  ∫ (A, B, C) 999999
    >> min ◁ A ◁ B ◁ C
CalculateMaxBounds : Bezier >> Point
    min =  999999 : Point
    max = -999999 : Point
    ∀ (A, B, C)
        if ¬(A.y = B.y ∧ B.y = C.y)
            min' = min ◁ A ◁ B ◁ C
            max' = max ▷ A ▷ B ▷ C
    >> (min, max)

CombineEdgeSamples () : EdgeSample >> SpanCoverage
  (x, y, A, H) = (0, 0, 0, 0)
  ∀ (x', y', a, h)
    if y' = y
      if x' = x
        (A', H') = (A + a, H + h)
      else
        (A', H') = (H + a, H + h)
        >> (x,     y, |A| ◁ 1,          1)
        >> (x + 1, y, |H| ◁ 1, x' - x - 1)
    else
      (A', H') = (a, h)
      >> (x, y, |A| ◁ 1, 1)
  >> (x, y, |A| ◁ 1, 1)

CombineEdgeSamples () : EdgeSample >> SpanCoverage
  ∫ (0, 0, 0, 0) (cx, cy, ca, ch, cl) (x, y, a, h)
    if y = cy ∧ x = cx
  
  ;min example
  Q 0 min (A, B, C)
    >> min ◁ A ◁ B ◁ C
  
  ; combine edge example
  ∫ (0, 0, 0, 0) (cx cy ca ch) (x y a h)
    if y = cy && x = cx
      >> (cx cy ca ch)
      >> (x, y, a + ca, h + ch)
    else
      >> (cx cy ca ch)
      >> (x y a h)
  ; OR
  Q (0, 0, 0, 0, 0) (cx cy ca ch chh cl) (x y a h)
    if y = cy
      if x = cx
        >> (x, y, a + ca, h + ch, chh, cl)
      else
        >> (cx cy ca ch chh cl)
        >> (x, y, a, h, ch, x - cx - 1)
    else
      >> (cx cy ca ch chh cl)
      >> (x, y, a, h, 0, 0)
  
  (x, y, A, H) = (0, 0, 0, 0)
  ∀ (x', y', a, h)
    if y' = y
      if x' = x
        (A', H') = (A + a, H + h)
      else
        (A', H') = (H + a, H + h)
        >> (x,     y, |A| ◁ 1,          1)
        >> (x + 1, y, |H| ◁ 1, x' - x - 1)
    else
      (A', H') = (a, h)
      >> (x, y, |A| ◁ 1, 1)
  >> (x, y, |A| ◁ 1, 1)
</code></pre><p>[todo: maybe talk somewhere about how I'm restricting my discussion to JUST the gezira source. I'm not aware of any other code written in Nile or planned to be written in Nile. I'm also assuming that all other user-end graphics programming can re-implement any missing feature, so unecessary features in gezira are actually unecessary.]</p><h3 class="section_heading">Texture</h3><p>Texturing is meant to happen directly after <code class="codeinline">Rasterize</code>. In fact <code class="codeinline">ApplyTexturer</code> is the only function in gezira that can take in <code class="codeinline">SpanCoverage</code> as input.</p><pre class="codeblock"><code>ApplyTexturer (t:Texturer) : SpanCoverage >> (Color, PointCoverage)
    → ExpandSpans () → DupZip (→ ExtractSamplePoints () → t,
                               → PassThrough ())
</code></pre><p>Pretty straightforward. <code class="codeinline">SpanCoverage</code>s get destructed, and then passed to a "texturer", which ends up binding pixel position, coverage, and color together.</p><p>A <code class="codeinline">Texturer</code> is just an alias of <code class="codeinline">Point >> Color</code>. So a pretty standard fragment-shader-like setup.</p><p>The version listed on the demo site is close enough. Instead of passing in a <code class="codeinline">Texturer</code> the pipeline is just hardcoded. In the "latest" source there are a couple functions that do the work of making the texturing pipeline for you.</p><h4>Gradient</h3><p>All preprogrammed "textures" in Gezira are gradients. Linear and radial are your two options.</p><p>There's no reason why this has to be the case, it's just e.g. bitmapped texture functionality isn't present in the Gezira source. All that's required is the ability to do single point lookups. So texture UV coordinates would have to be carried in a parellel stream.</p><p>That being said there are also some functions that manipulate <code class="codeinline">ColorSpan</code>s. Those aren't used in the demo and I don't know how they're supposed to be used. [todo: remove]</p><p>In the demo, this is done in the most obvious way. It pipes each <code class="codeinline">SpanCoverage</code> through a couple functions to choose a color for that point, and then constructs a pixel. [todo: move up?]</p><pre class="codeblock"><code>ProjectLinearGradient (A:Point, B:Point) : Point >> Number
    v   = B - A
    Δs  = v / (v ∙ v)
    s00 = A ∙ Δs
    ∀ P
        >> P ∙ Δs - s00
</code></pre><p>Unlike the previous functions, this one starts showing off how parameters work in Nile. It looks functional, like <code class="codeinline">ProjectLinearGradient</code> is a function taking two points, whose return value is a function <code class="codeinline">PointCoverage >> Real</code>. But that's not quite right. It returns an object that transforms <i>streams</i>, like with <code class="codeinline">CombineEdgeSamples</code> above. [todo: re-explain this] [todo: this is just wrong]</p><p>Unlike the previous functions, this one starts showing off how parameters work in Nile. They're a way to pass in values that are constant for the entire input stream.</p><p>In the demo source, this is typed as <code class="codeinline">PointCoverage >> Real</code>, to make the pipeline easier.</p><p>In the "official" source, this function is called just <code class="codeinline">LinearGradient</code>. I don't know where the "Project" part came from.</p><p>Not much more to say about this one. Very nice and succinct.</p><pre class="codeblock"><code>PadGradient () : Real >> Real
    ∀ s
        >> 0 ▷ s ◁ 1
</code></pre><p>On the demo page, the source listing is wrong. It should be typed <code class="codeinline">Real >> Real</code>. Transcription error?</p><p>I also don't know why this is called "padding" a gradient. But this terminology is also used in SVG, so what do I know?</p><p>This one is split off from <code class="codeinline">LinearGradient</code> because, in the source, there are 2 other gradient manipulation functions: <code class="codeinline">RepeatGradient</code> and <code class="codeinline">ReflectGradient</code>. <code class="codeinline">PadGradient</code> is meant to be useful for both <code class="codeinline">LinearGradient</code> and <code class="codeinline">RadialGradient</code>.</p><p>Funnily, there's also a <code class="codeinline">PadTexture</code>, <code class="codeinline">RepeatTexture</code>, and <code class="codeinline">ReflectTexture</code> in the full source. These could be used instead. You can manipulate the incoming <code class="codeinline">Point</code> as opposed to manipulating the outgoing Real. That would have saved 10 lines.</p><pre class="codeblock"><code>GradientSpan (A:Color, a:Number, B:Color, b:Number) : (Number, Color) >> (Number, Color)
    ∀ (s, C)
        α = (b - s) / (b - a)
        D = { αA + (1 - α)B, if a ≤ s ≤ b
              C,             otherwise    }
        >> (s, D)
</code></pre><p>In the demo source, this is written a bit different:</p><pre class="codeblock"><code>GradientSpan (A:Color, B:Color) : Real >> Color
  ∀ s
    >> sA + (1 - s)B
</code></pre><p>Not sure why that was changed. In any event, this one is pretty simple too.</p><pre class="codeblock"><code>ZipPixels () : (PointCoverage, Color) >> Pixel
  ∀ ((x, y, coverage), (r, g, b, a))
    >> ((x, y), (r, g, b, a * coverage))
</code></pre><p>This one isn't present in the "latest" source. I bring this one up because the rest of the source also uses premultiplied alpha. I gather there's supposed to be some user-provided special code to do the final composite and get rid of the alphas? [todo: check this.]</p><h3 class="section_heading">Stroke</h3><p>Stroking is done by offsetting a curve in both directions, capping the ends, and then using the rendering functions above to render the stroke as a solid shape.</p><p>When I was first looking to gezira, I thought the choice of bezier as the drawing primitive was a little odd. Stroking is one of gezira's main features, and it's well known that the offset shape of a quadratic bezier is NOT a quadratic bezier.</p><p>I believe the intended usage of the gezira stroking API is to first subdivide the shape into piecewise nearly linear pieces before stroking. Such a function doesn't appear in the gezira source, but it is how I see it used in some of the demos.</p><p>After learning that, I thought "ah, I see. Beziers are chosen as the base primitive because they come with tangent information at the ends. This makes stroking easier, since there's no need to join connected curves, which would be hard using this streaming language."</p><p>But no, it does join connected curves. This is interesting because to join curves you need to look at <i>pairs</i> of connected curves to get the angle right.</p><p>[todo: image of non-connected curves, and connected ones]</p><p>The streams we've looked at so far operate on one item at a time, so we're about to see something different.</p><p>Before I continue, it's important to note that the hidden stroke demo on Bret Victor's demo site doesn't do anything even close to what the gezira source says. So there's no hope trying to read the page source to figure anything out.</p><p>Stroking works by duplicating the input stream, stroking one side of the path, reversing, and then stroking the other.</p><pre class="codeblock"><code>StrokeBezierPath (width:Number, limit:Number, cap:Number) : Bezier >> Bezier
    → SanitizeBezierPath () →
      DupCat (→ StrokeOneSide (width, limit, cap),
              → Reverse () → ReverseBeziers () → StrokeOneSide (width, limit, cap))
</code></pre><p><code class="codeinline">DupCat</code> and <code class="codeinline">Reverse</code> here are built-in. They does what they say on the tin. Notice that <code class="codeinline">DupCat</code> takes streams as arguments. I will NOT be talking about that.</p><p><code class="codeinline">StrokeOneSide</code> always strokes the left side of a curve, and on non-closed curves always caps the final curve. So reversing and stroking creates a full closed shape that can be passed to <code class="codeinline">Rasterize</code>. The closed path comes out in the right order too, so you could potentially <code class="codeinline">→ StrokeBezierPath (...) → StrokeBezierPath (...)</code> to do some cool effects.</p><p>I won't list <code class="codeinline">SanitizeBezierPath</code>. It just checks if the control point is roughly colinear with the endpoints, and if so replaces them with one or more less pathological bezier.</p><p><code class="codeinline">ReverseBeziers</code> also does what it says on the tin. I won't list that either.</p><p><code class="codeinline">StrokeOneSide</code> is where it gets weird.</p><pre class="codeblock"><code>OffsetAndJoin (Zi:Bezier, Z1:Bezier, o:Number, l:Number, c:Number) : Bezier >> Bezier
    ∀ Zj
        → OffsetAndJoin (Zj, Z1, o, l, c) →
          JoinBeziers   (Zi, Zj, o, l)    → OffsetBezier (Zi, o)
    if Zi.C = Z1.A
        → JoinBeziers (Zi, Z1, o, l) → OffsetBezier (Zi, o)
    else
        → CapBezier (Zi, o, c)       → OffsetBezier (Zi, o)

StrokeOneSide (width:Number, limit:Number, cap:Number) : Bezier >> Bezier
    ∀ Z1
        → OffsetAndJoin (Z1, Z1, width / 2, limit, cap)
</code></pre><p>The <code class="codeinline">width</code> parameter is the width of the stroke, obviously. <code class="codeinline">limit</code> is the miter limit, which can be set negative to choose round joins. <code class="codeinline">cap</code> is set positive or negative to choose between rounded or square caps.</p><p>If you squint at it, you can see the shape of the pipeline. <code class="codeinline">JoinBeziers</code> emits geometry to join two beziers. <code class="codeinline">OffsetBezier</code> offsets beziers to the left. And there's some kind of recursion going on. Then at the end, either <code class="codeinline">CapBezier</code> the last curve or <code class="codeinline">JoinBeziers</code> the first and last curve.</p><p>But looking at it more closely is, I think, confusing. The new syntax of <code class="codeinline">∀ x; → Stage (x)</code> is very non-obvious in its mechanics. The switch from <code class="codeinline"><<</code> style recursion to this more traditional style is also confusing.</p><p>Since this snippet is a bit noisy, here's a simplified version of this pattern:</p><pre class="codeblock"><code>Stage3 (a: Number, b: Number) : Number >> Number
  t = 10
  >> (ta + b)

Stage2 (a: Number) : Number >> Number
  ∀ b
    → Stage2 (b) → Stage3 (a, b)

Stage1 () : Number >> Number
  ∀ a
    → Stage2 (a)
</code></pre><p>You do this weird double <code class="codeinline">∀</code> thing across two different stages, where the second stage starts with a recursion. Then stage 3 gets adjacent pairs as arguments that you can do whatever you want with!</p><p>Here, feeding the stream <code class="codeinline">(1, 2, 3, 4, 5, 6, 7, 8, 9)</code> into the pipeline <code class="codeinline">→ Stage1 ()</code> gives back the stream <code class="codeinline">(12, 23, 34, 45, 56, 67, 78, 89)</code>, as expected.</p><p>So what's the deal with this new syntax? It seems like a weird hack that depends on the specific way that streams in Nile work. The pseudocode looks something like this:</p><pre class="codeblock"><code>handle_process(env, proc) {
  // Handle loop prologue.
  // This is where pipeline statements would normally go.

  // Handle loop.
  while (input_stream.non_empty()) {
    a = input_stream.consume();
    
    // Evaluate/deconstruct/whatever the input, bind it to the loop variable, add it to the env's symbol table.
    bind(env, proc.loop.vars, a);
    
    // Do whatever the loop body says.
    // Normally that involves pushing onto the output_stream or back onto the top of the input_stream.
    // Any pipeline statements are run, with the current input_stream.
    // Normally nothing gets returned.
    // But not in this example. Here, a pipeline gets returned.
    body = eval(env, proc.loop.body);
    
    if (body is a pipeline) {
      // Kill the loop
      return;
    }
  }
  
  // Handle loop epilogue.
}
</code></pre><p>There are 3 weird things that go into this.</p><p>First, the <code class="codeinline">∀ x; → StageN ()</code> will consume one item from the input stream before running <code class="codeinline">StageN</code>. This means that <code class="codeinline">StageN</code> will see one less item than <code class="codeinline">StageN-1</code>. So if <code class="codeinline">Stage1</code> gets run on the input stream <code class="codeinline">(1, 2, 3, 4)</code>, <code class="codeinline">Stage2</code> will get run with <code class="codeinline">(2, 3, 4)</code>.</p><p>Second, the <code class="codeinline">∀ x; → StageN ()</code> will break after the first item is removed.</p><p>The end result is that the <code class="codeinline">∀ x; → StageN ()</code> pattern has the effect of removing the top item from the input stream before running <code class="codeinline">StageN</code>.</p><p>You may have noticed that <code class="codeinline">Stage2</code> is written as <code class="codeinline">→ Stage2 (b) → Stage3 (a, b)</code> and not <code class="codeinline">→ Stage3 (a, b) → Stage2 (b)</code>. Wouldn't that mean that the the pairs will come out in reverse order?</p><p>Not quite. The third weird thing is the handling of processes that don't return a pipeline or consume all the input with a <code class="codeinline">∀</code> loop. At the end of their execution, they're assumed to have an implicit pass-through stage at the very end. The pass-through stage is special, and has the special syntax of <code class="codeinline">(→)</code>, but it's also not used much explicitly.</p><p>So if you were to call <code class="codeinline">Stage3 (9, 9)</code> on <code class="codeinline">(1, 2, 3)</code>, the output will be <code class="codeinline">(99, 1, 2, 3)</code>.</p><p>The final call to <code class="codeinline">Stage2</code> ends with a pipeline in a backwards order like <code class="codeinline">Stage3(8, 9) → Stage3(7, 8) → Stage3(6, 7) ... → Stage3(2, 3) → Stage3(1, 2)</code>. Regardless the output will be in the correct order because each <code class="codeinline">Stage3</code> inserts its own item into the first position.</p><p>Also, this means that <code class="codeinline">∀ b; → Stage3 (a, b) → Stage2 (b)</code> wouldn't even work; it would infinitely recurse since <code class="codeinline">∀ b</code> will keep taking one item off and <code class="codeinline">Stage3</code> will keep putting one back on.</p><p>That's also what's going on with the weird order of <code class="codeinline">→ JoinBeziers (...) → OffsetBezier (...)</code> and the rest.</p><p>My commentary on this is that it's all very weird. Like, what a strange syntax for what's essentially a <code class="codeinline">peek</code> operation, or a <code class="codeinline">DupZip((→), → RotateOne ())</code>.</p><p>I'm pretty sure I've written pipelines that work like this. But to my credit I also haven't published that code to the world saying "this is the official way to implement peek in my streaming language, and also this is the Maxwell's equations of rendering."</p><p>Maybe that was a little harsh. As far as I've seen, Dan Amelang has never said the Maxwell line.</p><p>Interestingly, there <i>was</i> a <code class="codeinline">peek</code> operator in the language, but it was removed! Here's a process from an old version of the gezira stroking system:</p><pre class="codeblock"><code>PrepareBeziersForJoin : Bezier >> (Bezier, Bezier)
    & (A, B, C)
    first = 1
    D = 0 : Point
    E = 0 : Point
    F = 0 : Point
    ∀ (D', E', F')
        if first
            first' = 0
        else
            >> ((D, E, F), (D', E', F')) >> ((F', E', D'), (F, E, D))
    if A = F ∧ first = 0
        >> ((D, E, F), (A, B, C)) >> ((C, B, A), (F, E, D))
</code></pre><p>Here the <code class="codeinline">&</code> operator peek, binding to <code class="codeinline">(A,B,C)</code>. Presumably <code class="codeinline">&</code> was chosen because Dan didn't have time to pour over the unicode table to find something else, and so he begrungingly using a character already on his keyboard, whincing with every keystroke. Maybe that was a little harsh too.</p><p>Personally, I don't see what's wrong with <code class="codeinline">peek</code>. It's a very normal thing to do with streams. It's the most obvious way to implement join/cap.</p><p>Another thing to note is the different kind of recursion. In the rasterization code, recursion was done with the <code class="codeinline"><<</code> operator, inserting data back into the input stream.</p><pre class="codeblock"><code>OffsetBezier (Z:Bezier, o:Number) : Bezier >> Bezier
    ϵ = 0.1
    (A, B, C) = Z
    (u, v)    = (A ⟂ B, B ⟂ C)
    M         = (A ~ B) ~ (B ~ C)
    if u ∙ v ≥ 1 - ϵ
        w = (A ~ B) ⟂ (B ~ C)
        D = A + ou
        F = C + ov
        N = M + ow
        E = N + (N - (D ~ F))
        >> (D, E, F)
    else if A ≠ B ≠ C
        → OffsetBezier ((M, B ~ C, C), o) → OffsetBezier ((A, A ~ B, M), o)
</code></pre><p>Here, the job of <code class="codeinline">OffsetBezier</code> is to emit beziers that are offset to the left. If the bezier isn't linear enough, split and recurse.</p><p>In the rendering code, this would have been implemented with <code class="codeinline">>></code> and <code class="codeinline"><<</code>. But here it can't. Because it can't have a <code class="codeinline">∀</code> loop in its body. Because its input stream isn't being fed raw beziers, only already-offset beziers. Because the raw beziers being stored in the input stream, they're being stored in the call stack. Because of this weird way of writing peek.</p><p>I think its existance also begs the question of why there are two versions of recursion. The <code class="codeinline">∀ x; → Self</code> concept can do everything the <code class="codeinline"><<</code> concept can and more. So why have both?</p><p>I have a couple suggestions here.</p><p>The simplest thing I would do is change the <code class="codeinline">∀ x; → </code> syntax. I think that the semantics are needlessly confusing.</p><p>I think an operator should be introduced that always pulls a single item out of the input stream. No option to sometimes continue. This removes the possibility of cursed processes like this:</p><pre class="codeblock"><code>Cursed () : Number >> Number
  -- Discard the first number >= 10, leaves the rest.
  ∀ x
    if x < 10 = 0
      >> x
    else
      → (→)
</code></pre><p>It would still need to be a block operator, since it can only work when the input stream is nonempty. I suggest <code class="codeinline">\{x}</code>:</p><pre class="codeblock"><code>AddOneFirst () : Number >> Number
  -- Adds one to the first number, leaves the rest
  \{x}
    >> (x + 1)
</code></pre><p><code class="codeinline">\{x}</code> is chosen because it looks like removing an element from a set. You could also go with <code class="codeinline">∃</code> of course for consistency.</p><p>I'd suggest maybe repurposing the <code class="codeinline">→ Proc ()</code> syntax in these blocks to mean "call Proc, but only on one item". Functions are meant to work on streams, and they should, but there's no reason why they can't be called with just one item.</p><p>In the gezira stroking source there are a couple special purpose functions for miter vs round join, round vs square cap. Imagining that they were rewritten to work off of the input stream, it'd be nice to be able to call them from a conditional, like</p><pre class="codeblock"><code>if should_join
  if should_miter
    (B1, B2) → MiterJoin ()
  else
    (B1, B2) → RoundJoin ()
else
  if should_square
    B1 → SquareCap ()
  else
    B1 → RoundCap ()
</code></pre><p>This is currently not possible if these functions take different input types.</p><p>This one I'm not as sure about, since now we're talking about multiple input and output streams, possibly multiple per call stack. I don't know how well this lines up with the VPRI vision.</p><p>Finally, I think the addition of a <code class="codeinline">RotateOne</code> function would let you write a stroke process that's more stylistically similar to the rasterization code. It would take the element on top of the input stream and put it on the bottom. You can implement <code class="codeinline">RotateOne</code> using the current syntax like this:</p><pre class="codeblock"><code>AppendEnd (end: Number) : Number >> Number
  ∀ x
    >> x
  >> end

RotateOne () : Number >> Number
  ∀ x
    → AppendEnd (x)
</code></pre><p>Now you could zip pairs together:</p><pre class="codeblock"><code>StrokeBezierPath_2 (width:Number, limit:Number, cap:Number) : Bezier >> Bezier
    → SanitizeBezierPath () →
      DupCat (→ (→),
              → Reverse () → ReverseBeziers ()) →
      DupZip (→ (→),
              → RotateOne ()) →
      OffsetAndJoin_2 (width, limit, cap)
</code></pre><p>Now a modified <code class="codeinline">OffsetAndJoin_2</code> receives adjacent <code class="codeinline">(Bezier, Bezier)</code> pairs in its input stream, along with 2 <code class="codeinline">(start, end)</code> and <code class="codeinline">(end, start)</code> pairs in the appropriate spots in the stream.</p><p>In the original code, caps were only ever added to curve ends, and joins were always applied between adjacent no matter what. But what if the stream contains just 2 beziers that aren't connected? The join will be messed up, and there won't be enough caps.</p><p>I suggest instead making the determination just based on bezier pairs. If adjacent pairs are touching, emit a join. If they aren't touching, emit a cap.</p><pre class="codeblock"><code>OffsetAndJoin_2 (o:Number, l:Number, c:Number) : (Bezier, Bezier) >> Bezier
    ∀ ((A, B, C), (D, E, F))
        -- offset (A, B, C)
        
        if C = D
            -- endpoints are touching, this is a join
        else
            -- endpoints are not touching, this is a cap
</code></pre><h3 class="section_heading">Closing</h3><p>I think I really scraped the bottom of the barrel on everything interesting about gezira. Here are maybe some extra things for looking at if I ever find myself wanting more.</p><p>I didn't really look at the filtering code in gezira. I'm not too interested in it at the moment, but it's there.</p><p>There's a tons and tons of code at <a href="https://tinlizzie.org/updates/">here</a>, and I have no idea what any of it does. It's almost certainly an interesting dive into the history of squeak (of which I know very little), VPRI, and Alan Kay's projects.</p><p>I want to mention <a href="https://github.com/Twinside/Rasterific">Rasterific</a>, if only because of how much work was put into it. It's a Haskell reimplementation of gezira. It emulates the gezira algorithm, but all in Haskell. It also significantly expands the set of operations. There are cubic beziers, dashed strokes, [todo: more]. It was started back in 2013.</p><p>I said at the beginning that Frank was never released. However, there is a build for iPad <a href="https://tinlizzie.org/~bert/frank4ipad/">sitting on the tinlizzie server</a>. I don't have an old 2011 jailbroken iPad sitting around, but I think it'd be super cool if someone installed it showed it off.</p><p>What was HARC? I only know keywords. How was it funded? How did it die? What was worked on in the interviening years? Since they weren't taking government grant money, they stopped publishing progress reports, so it's hard to know what it even was. Was Ohm its only output?</p><p>[todo: more things to look into]</p><p>What are the main people up to these days?</p><p>Alan Kay is getting up there in age. He's 85 now. Hopefully he's enjoying retirement.</p><p>Dan Amelang: who knows? He's very much the main character of this post, but outside of this work I don't know much about him. He's still alive, but as for what he's working on? No idea.</p><p>Professor Ian Piumarta: still active, still doing much the same sort of research.</p><p>Alex Warth: still active, still doing much the same sort of research. I saw the talk he gave at at (with?) the Ink & Switch people last year.</p><p>Yoshiki Ohshima: still quite active. Tons of projects. He updates https://tinlizzie.org/ohshima/ often with his new projects and accomplishments.</p><p>I definitely think there's more to explore. For example, I made a couple changes that allows me to do subpixel rendering:</p><p><table><tr style="vertical-align:top"><td width=33.333%><figure><img src="letter_g.svg" style="width:100%"><figcaption>What is a subpixel rendering demo without text? This is Liberation Serif's g. Liberation Serif is distributed as a TrueType font, which uses quadratic beziers for shape outlines.</figcaption></figure></td><td width=33.333%><figure><img src="letter_g_subpixel_2.svg" style="width:100%"><figcaption>Subpixel coverage.</figcaption></figure></td><td width=33.333%><figure><img src="letter_g_subpixel.svg" style="width:100%"><figcaption>Simulation of what this looks like rendered.</figcaption></figure></td></tr></table></p><p>I aught to address my opinions on this whole thing.</p><p>[todo: my opinions on the VPRI goal as a whole]The whole conceit, the practicality and beauty and <i>rightness</i> of a computing stack redone through radical simplicity, is a siren song to me. Distressing, impossible to ignore, and dangerous.</p><p>I also think that such an endeavor is doomed to fail. I have so many thoughts on this, from so many different angles, I couldn't possibly write them all down here.</p><p>That being said I try to follow the call in my own way. I'm writing this post in a homemade text editor, building the site with a homemade static site generator, on one of those build-your-own linux systems called Guix. I have tons of homemade tools that I use every day, on my computers, my phone, my watch, my home. Every time I use a piece of software someone else wrote my first thought is "I could definitely make my own version."</p><p>If I were running Fedora, I'd alias <code class="codeinline">yum</code> to <code class="codeinline">yuck</code>.</p><p>Let's elide any discussion of what these behaviors mean about me, and if they've affected my life in a positive or negative way.</p><p>I read a lot about weird computing systems and computing models and other big theory-of-everything projects like the VPRI. Probably far more than is healthy. Ranking the VPRI among them all, I'd give them a thumbs up. Pretty cool.</p><p>The first couple years saw tons of progress. If that velocity had been maintained through the years, that would have been incredible.</p><p>I would have liked to see more detailed output. The progress reports are nice, but they aren't that detailed. The more traditional papers were nice, and I would have loved to see more of those, specifically focused on things that were <i>actually in the running system!</i></p><p>The irony here is that Alan Kay has probably said more words on camera than I've said in my entire life. But I don't want to hear your Maxwell's equations metaphor! I want teardowns! Like this!</p><p>I feel I've been spoiled when it comes to this. I tune in monthly to read 100 rabbit's progress reports. The entirety of Dynamicland's archives are an incredible read. I get to live vicariously through these, and others.</p><p>They are a safe way of engaging with projects and ideas that enamor me. I don't have to deal with the messy, human part of these projects. I don't have to deal with my own emotions about messing up something others depend on/find joy in, or about publicly falling short.</p><p>Most of all I don't have to be in the thick of it, seeing all the gory details and compromises, and see the magic fade away.</p><p>Which brings me to my next question: did gezira accomplish its goal?</p><p>[todo: my opinion on "has gezira accomplished its goal? alan kay's goal?"]</p><p>[todo: my opinions on gezira as a whole]</p></div><div style="background-color: #222; padding: 1em; color: #fafafa">Written by Daniel Taylor.<br>Email: contact@djtaylor.me<br><br><span style="color: #aaa">© 2024 by Daniel Taylor</span></div><script id="MathJax-script" async src="/3rd-party/mathjax/tex-mml-chtml.js"></script><script>window.MathJax = { tex: { inlineMath: [['$', '$']] } };</script></body></html>